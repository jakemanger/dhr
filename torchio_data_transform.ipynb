{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Config\n",
    "seed = 42  # for reproducibility\n",
    "training_split_ratio = 0.75\n",
    "num_epochs = 5\n",
    "\n",
    "# If the following values are False, the models will be downloaded and not computed\n",
    "compute_histograms = False\n",
    "train_whole_images = False \n",
    "train_patches = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install the following via terminal\n",
    "```bash\n",
    "sudo apt install tree\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install some pypi packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "!pip install --quiet --upgrade pip\n",
    "!pip install --quiet unet==0.7.7\n",
    "!pip install --quiet torchio==0.18.33"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install pytorch following recommendations at https://pytorch.org/\n",
    "\n",
    "For me, this was running the following command:\n",
    "\n",
    "```bash\n",
    "pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import enum\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchio as tio\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch.nn\n",
    "import monai\n",
    "\n",
    "import numpy as np\n",
    "from unet import UNet\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "\n",
    "print('TorchIO version:', tio.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TorchIO version: 0.18.33\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data\n",
    "# Viewing dataset files\n",
    "We will use the tree program to view our file structure"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# dataset_dir_name = 'dataset'\n",
    "\n",
    "# !tree -d {dataset_dir_name}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Making the subjects dataset\n",
    "This is a torchio data format that lets you easily modify the subjects with transforms (e.g. to generate new training data via data augmentation) and load it efficiently to the model with a DataLoader.\n",
    "\n",
    "It receives as input a list of torchio.Subject instances and an optional torchio.transforms.Transform.\n",
    "\n",
    "The inputs to the subject class are instances of torchio.Image, such as torchio.ScalarImage (for scalars) or torchio.LabelMap (for categories). The image class will be used by the transforms to decide whether or not to perform the operation. For example, spatial transforms must apply to both, but intensity transforms must apply to scalar images only."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# image_dir = f'{dataset_dir_name}/crab_images_10/'\n",
    "# label_dir = f'{dataset_dir_name}/crab_labels_10/'\n",
    "\n",
    "# # find all the .nii files\n",
    "# images = []\n",
    "# labels = []\n",
    "\n",
    "# for file in os.listdir(image_dir):\n",
    "#     if file.endswith('.nii'):\n",
    "#         images.append(image_dir + file)\n",
    "        \n",
    "# for file in os.listdir(label_dir):\n",
    "#     if file.endswith('.nii'):\n",
    "#         labels.append(label_dir + file)\n",
    "\n",
    "\n",
    "# # find the matching pairs by their filename\n",
    "# images_p = []\n",
    "# for img in images:\n",
    "#     images_p.append(Path(img).stem)\n",
    "    \n",
    "# labels_p = []\n",
    "# for label in labels:\n",
    "#     name = (Path(label).stem).replace('_corneas', '').replace('_rhabdoms', '')\n",
    "#     labels_p.append(name)\n",
    "    \n",
    "# filenames = sorted(list(set(images_p) & set(labels_p)))\n",
    "\n",
    "# print(f'Found {len(filenames)} labelled images for analysis')\n",
    "\n",
    "# # now add them to a list of subjects\n",
    "# subjects_list = []\n",
    "\n",
    "# for filename in filenames:\n",
    "#     subject = tio.Subject(\n",
    "#         image=tio.ScalarImage(image_dir + filename + '.nii', check_nans=True),\n",
    "#         label_corneas=tio.Image(label_dir + filename + '_corneas.nii', type=tio.LABEL, check_nans=True),\n",
    "#         label_rhabdoms=tio.Image(label_dir + filename + '_rhabdoms.nii', type=tio.LABEL, check_nans=True),\n",
    "#         filename=filename\n",
    "#     )\n",
    "#     subjects_list.append(subject)\n",
    "\n",
    "# # and finally create a SubjectsDataset\n",
    "# dataset = tio.SubjectsDataset(subjects_list)\n",
    "# print('Created a SubjectsDataset')\n",
    "# print(f'Dataset size: {len(dataset)} subjects')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's take a look at one of the subjects in the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# one_subject = dataset[0]\n",
    "# one_subject.plot()\n",
    "# print(one_subject)\n",
    "# print(one_subject.image)\n",
    "# print(one_subject.label_corneas)\n",
    "# print(one_subject.label_rhabdoms)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explore transforms\n",
    "### Intensity transforms\n",
    "We will use the HistogramStandardization and the ZNormalization transforms to standardise and normalize our image intensity.\n",
    "\n",
    "The images have been acquired by different mct scanners with different fixation and staining methods. We will apply some normalization techniques so that intensities are similarly distributed and within similar ranges.\n",
    "\n",
    "#### Histogram Standardization\n",
    "This method is an implementation of [New variants of a method of MRI scale standardization](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.204.102&rep=rep1&type=pdf).\n",
    "The main problem that this method intends to fix is that absolute intensity values do not have a fixed meaning. Intensity values can be highly dependent on fixation, staining and scanning procedures.\n",
    "This method intends to make transformed images have intensities values with the same tissue meaning. It does this by defining landmarks aross all images and then deforms the histogram to match that of the trained mean histogram.\n",
    "\n",
    "To remove the effect of the background (usually zeros in mct scans), and only recognise tissue features in the foreground, we will use a masking function that only uses values greater than the mean.\n",
    "\n",
    "We test whether the mean gets the foreground values quite well below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# image_thresholded = copy.deepcopy(dataset[0])\n",
    "# data = image_thresholded.image.data\n",
    "# data[data > data.float().mean()] = data.max()\n",
    "# image_thresholded.plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks like it does quite a good job. Now let's calculate the landmarks for the foregrounds."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# landmarks = tio.HistogramStandardization.train(\n",
    "#     images,\n",
    "#     output_path='landmarks.npy',\n",
    "#     masking_function=tio.ZNormalization.mean\n",
    "# )\n",
    "# np.set_printoptions(suppress=True, precision=3)\n",
    "# print('\\nTrained landmarks:', landmarks)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Augmentation\n",
    "We will use a variety of augmentation methods:\n",
    "- RandomAnisotropy\n",
    "- RandomBlur\n",
    "- RandomNoise\n",
    "- OneOf\n",
    "    - RandomAffine\n",
    "    - RandomElasticDeformation\n",
    "- OneOf\n",
    "    - RandomMotion\n",
    "    - RandomGhosting # perhaps not applicable to micro-ct?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# import napari\n",
    "# viewer = napari.view_image(znormed.image.numpy(), name='transformed intensity image', ndisplay=3)\n",
    "# viewer.add_image(dataset[0].image.numpy(), name='original image')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}