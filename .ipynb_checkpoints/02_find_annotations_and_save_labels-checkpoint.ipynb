{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have organised all the files into your `raw_image_info.csv` file, we now need to generate the raw_label images to train our model. These will be calculated based off the raw_labels found in `raw_annotated_file_path`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %gui qt5\n",
    "import torch\n",
    "import torchio as tio\n",
    "from torch.utils.data import DataLoader\n",
    "import scipy.io\n",
    "from scipy.ndimage import maximum_filter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import napari\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have volumes of micro-ct data that we are trying to label. However, the labels we currently have are 3d point locations, which isn't a format that our deep learning model can link spatially to our ct data. \n",
    "\n",
    "We want to convert these 3d point locations into a new \"prediction volume\". This is what we want our deep learning model to end up producing. It is also a format that our deep learning model can read, link spatially to our data and produce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load in the info we need from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file_path</th>\n",
       "      <th>status</th>\n",
       "      <th>crop</th>\n",
       "      <th>strange rhabdom pos</th>\n",
       "      <th>swap_xy</th>\n",
       "      <th>flip_y</th>\n",
       "      <th>check</th>\n",
       "      <th>old_swap_xy</th>\n",
       "      <th>old_flip_y</th>\n",
       "      <th>OLD check</th>\n",
       "      <th>has correct spacing</th>\n",
       "      <th>needs_cropping_after_creation</th>\n",
       "      <th>raw_annotated_file_path</th>\n",
       "      <th>other notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/raw_images/diurnal_tarsata.nii</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>good</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/ants/diurna...</td>\n",
       "      <td>data with incorrect spacing have irregular siz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/raw_images/dampieri_20151218.nii</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>good</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/fiddlercrab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/raw_images/dampieri_20200218_male_left...</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>good (possibly hard to see missing ones at edges)</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/fiddlercrab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/raw_images/dampieri_male_16.nii</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>needs cropping</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/fiddlercrab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/raw_images/flammula_20180307.nii</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>good</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/fiddlercrab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataset/raw_images/flammula_20190925_male_left...</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>needs cropping</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/fiddlercrab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset/raw_images/flammula_20200327_female_le...</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>needs cropping</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/fiddlercrab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dataset/raw_images/neohelice_20190616_1_croppe...</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>needs cropping</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/fiddlercrab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dataset/raw_images/Hyperia_02_head_FEG190604_014C</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wrong orientation or image</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dataset/raw_images/Hyperia_01_head_FEG190604_014B</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>good</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dataset/raw_images/Leptocotis_02_head_FEG19021...</td>\n",
       "      <td>good</td>\n",
       "      <td>True</td>\n",
       "      <td>bottom of cone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong orientation or image</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/L...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dataset/raw_images/P_crassipes_FEG190213_003b_...</td>\n",
       "      <td>incomplete annotation</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>good</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dataset/raw_images/P_crassipes_FEG190801_034_0...</td>\n",
       "      <td>check in 3d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong orientation (needs x and z swapped inste...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dataset/raw_images/P_crassipes_FEG191022_077A_...</td>\n",
       "      <td>check in 3d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Wrong image file – can’t find matching image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dataset/raw_images/P_crassipes_FEG191022_077B.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>good</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dataset/raw_images/P_crassipes_FEG200129_099_c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>regenerate using these settings</td>\n",
       "      <td>has weird double z axis</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dataset/raw_images/P_crassipes_FEG200205_108_c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dataset/raw_images/P_gracilis_FEG190213_003a_h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dataset/raw_images/P_robisoni_FEG200205_105-head</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dataset/raw_images/Paraphronima_FEG181024_03_h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dataset/raw_images/Paraphronima_FEG181024_head...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>good, but looks like rhabdoms have been sucked...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dataset/raw_images/Paraphronima_FEG181024_head...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>good</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dataset/raw_images/Paraphronima_FEG191028_078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>good, but very small markers</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dataset/raw_images/Paraphronima_head_04_FEG200...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>good, but very small markers</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dataset/raw_images/Paraphronima_head_05_FEG200...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>orientation correct, but some rhabdoms have be...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dataset/raw_images/Phronima_04_FEG200107_089.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>good</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dataset/raw_images/Phronima_05_FEG200107_090.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>good</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dataset/raw_images/phronima_20180403.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>most of dorsal eyes done, needs cropping, but ...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dataset/raw_images/20190608_phronima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>good</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dataset/raw_images/Platyscelus_02_FEG191112_08...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong image or orientation</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dataset/raw_images/psyllid_20190906_female_eye...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>good</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/psyllids/ps...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>dataset/raw_images/psyllid_20190906_male_eye.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/psyllids/ps...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dataset/raw_images/flammula_male_23_6_left</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>incomplete and wrong orientation</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/fiddlercrab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dataset/raw_images/Brachyscelus.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>incomplete and wrong orientation</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>dataset/raw_images/platyscelus_01_downsampled.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>incomplete and wrong orientation</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dataset/raw_images/streetsia_20180409.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wrong orientation try regenerating using these...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>dataset/raw_images/streetsia_20190308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>good but right eye only</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dataset/raw_images/streetsia_20190325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wrong orientation try regenerating using these...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>//home/jake/projects/mctv_resfiles/hyperiids/s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image_file_path                 status  \\\n",
       "0              dataset/raw_images/diurnal_tarsata.nii                   good   \n",
       "1            dataset/raw_images/dampieri_20151218.nii                   good   \n",
       "2   dataset/raw_images/dampieri_20200218_male_left...                   good   \n",
       "3             dataset/raw_images/dampieri_male_16.nii                   good   \n",
       "4            dataset/raw_images/flammula_20180307.nii                   good   \n",
       "5   dataset/raw_images/flammula_20190925_male_left...                   good   \n",
       "6   dataset/raw_images/flammula_20200327_female_le...                   good   \n",
       "7   dataset/raw_images/neohelice_20190616_1_croppe...                   good   \n",
       "8   dataset/raw_images/Hyperia_02_head_FEG190604_014C                   good   \n",
       "9   dataset/raw_images/Hyperia_01_head_FEG190604_014B                   good   \n",
       "10  dataset/raw_images/Leptocotis_02_head_FEG19021...                   good   \n",
       "11  dataset/raw_images/P_crassipes_FEG190213_003b_...  incomplete annotation   \n",
       "12  dataset/raw_images/P_crassipes_FEG190801_034_0...            check in 3d   \n",
       "13  dataset/raw_images/P_crassipes_FEG191022_077A_...            check in 3d   \n",
       "14  dataset/raw_images/P_crassipes_FEG191022_077B.nii                    NaN   \n",
       "15  dataset/raw_images/P_crassipes_FEG200129_099_c...                    NaN   \n",
       "16  dataset/raw_images/P_crassipes_FEG200205_108_c...                    NaN   \n",
       "17  dataset/raw_images/P_gracilis_FEG190213_003a_h...                    NaN   \n",
       "18   dataset/raw_images/P_robisoni_FEG200205_105-head                    NaN   \n",
       "19  dataset/raw_images/Paraphronima_FEG181024_03_h...                    NaN   \n",
       "20  dataset/raw_images/Paraphronima_FEG181024_head...                    NaN   \n",
       "21  dataset/raw_images/Paraphronima_FEG181024_head...                    NaN   \n",
       "22      dataset/raw_images/Paraphronima_FEG191028_078                    NaN   \n",
       "23  dataset/raw_images/Paraphronima_head_04_FEG200...                    NaN   \n",
       "24  dataset/raw_images/Paraphronima_head_05_FEG200...                    NaN   \n",
       "25   dataset/raw_images/Phronima_04_FEG200107_089.nii                    NaN   \n",
       "26   dataset/raw_images/Phronima_05_FEG200107_090.nii                    NaN   \n",
       "27           dataset/raw_images/phronima_20180403.nii                    NaN   \n",
       "28               dataset/raw_images/20190608_phronima                    NaN   \n",
       "29  dataset/raw_images/Platyscelus_02_FEG191112_08...                    NaN   \n",
       "30  dataset/raw_images/psyllid_20190906_female_eye...                    NaN   \n",
       "31   dataset/raw_images/psyllid_20190906_male_eye.nii                    NaN   \n",
       "32         dataset/raw_images/flammula_male_23_6_left                    NaN   \n",
       "33                dataset/raw_images/Brachyscelus.nii                    NaN   \n",
       "34  dataset/raw_images/platyscelus_01_downsampled.nii                    NaN   \n",
       "35          dataset/raw_images/streetsia_20180409.nii                    NaN   \n",
       "36              dataset/raw_images/streetsia_20190308                    NaN   \n",
       "37              dataset/raw_images/streetsia_20190325                    NaN   \n",
       "\n",
       "     crop strange rhabdom pos  swap_xy  flip_y  check  old_swap_xy  \\\n",
       "0   False                 NaN    False   False    NaN        False   \n",
       "1   False                 NaN    False   False    NaN        False   \n",
       "2   False                 NaN    False   False    NaN        False   \n",
       "3    True                 NaN    False   False    NaN        False   \n",
       "4   False                 NaN    False   False    NaN        False   \n",
       "5    True                 NaN    False   False    NaN        False   \n",
       "6    True                 NaN    False   False    NaN        False   \n",
       "7    True                 NaN    False   False    NaN        False   \n",
       "8    True                 NaN    False   False    NaN        False   \n",
       "9   False                 NaN    False   False    NaN        False   \n",
       "10   True      bottom of cone    False   False    NaN         True   \n",
       "11   True                 NaN    False   False    NaN         True   \n",
       "12    NaN                 NaN    False   False    NaN         True   \n",
       "13    NaN                 NaN    False   False    NaN         True   \n",
       "14    NaN                 NaN    False   False    NaN         True   \n",
       "15    NaN                 NaN    False   False    NaN         True   \n",
       "16    NaN                 NaN    False   False    NaN         True   \n",
       "17    NaN                 NaN    False   False    NaN         True   \n",
       "18    NaN                 NaN    False   False    NaN         True   \n",
       "19    NaN                 NaN    False   False    NaN         True   \n",
       "20    NaN                 NaN    False   False    NaN         True   \n",
       "21    NaN                 NaN    False   False    NaN         True   \n",
       "22    NaN                 NaN    False   False    NaN         True   \n",
       "23    NaN                 NaN    False   False    NaN         True   \n",
       "24    NaN                 NaN    False   False    NaN         True   \n",
       "25    NaN                 NaN    False   False    NaN        False   \n",
       "26    NaN                 NaN    False   False    NaN        False   \n",
       "27    NaN                 NaN    False   False    NaN        False   \n",
       "28    NaN                 NaN    False   False    NaN         True   \n",
       "29    NaN                 NaN    False   False    NaN         True   \n",
       "30    NaN                 NaN    False   False    NaN        False   \n",
       "31    NaN                 NaN    False   False    NaN        False   \n",
       "32    NaN                 NaN    False   False    NaN         True   \n",
       "33    NaN                 NaN    False   False    NaN         True   \n",
       "34    NaN                 NaN    False   False    NaN         True   \n",
       "35    NaN                 NaN    False   False    NaN        False   \n",
       "36    NaN                 NaN    False   False    NaN         True   \n",
       "37    NaN                 NaN    False   False    NaN        False   \n",
       "\n",
       "    old_flip_y                                          OLD check  \\\n",
       "0        False                                               good   \n",
       "1        False                                               good   \n",
       "2        False  good (possibly hard to see missing ones at edges)   \n",
       "3        False                                     needs cropping   \n",
       "4        False                                               good   \n",
       "5        False                                     needs cropping   \n",
       "6        False                                     needs cropping   \n",
       "7        False                                     needs cropping   \n",
       "8        False                         wrong orientation or image   \n",
       "9        False                                               good   \n",
       "10        True                         wrong orientation or image   \n",
       "11        True                                               good   \n",
       "12        True  wrong orientation (needs x and z swapped inste...   \n",
       "13        True       Wrong image file – can’t find matching image   \n",
       "14        True                                               good   \n",
       "15       False                    regenerate using these settings   \n",
       "16        True                                        wrong image   \n",
       "17        True                                        wrong image   \n",
       "18        True                                        wrong image   \n",
       "19        True                                        wrong image   \n",
       "20        True  good, but looks like rhabdoms have been sucked...   \n",
       "21        True                                               good   \n",
       "22        True                       good, but very small markers   \n",
       "23        True                       good, but very small markers   \n",
       "24        True  orientation correct, but some rhabdoms have be...   \n",
       "25       False                                               good   \n",
       "26       False                                               good   \n",
       "27       False  most of dorsal eyes done, needs cropping, but ...   \n",
       "28        True                                               good   \n",
       "29        True                         wrong image or orientation   \n",
       "30       False                                               good   \n",
       "31       False                                         incomplete   \n",
       "32        True                   incomplete and wrong orientation   \n",
       "33        True                   incomplete and wrong orientation   \n",
       "34        True                   incomplete and wrong orientation   \n",
       "35       False  wrong orientation try regenerating using these...   \n",
       "36        True                            good but right eye only   \n",
       "37       False  wrong orientation try regenerating using these...   \n",
       "\n",
       "        has correct spacing  needs_cropping_after_creation  \\\n",
       "0                     FALSE                          False   \n",
       "1                     FALSE                          False   \n",
       "2                     FALSE                          False   \n",
       "3                     FALSE                           True   \n",
       "4                     FALSE                          False   \n",
       "5                     FALSE                           True   \n",
       "6                     FALSE                           True   \n",
       "7                     FALSE                           True   \n",
       "8                     FALSE                          False   \n",
       "9                     FALSE                          False   \n",
       "10                     TRUE                           True   \n",
       "11                     TRUE                          False   \n",
       "12                     TRUE                          False   \n",
       "13                      NaN                          False   \n",
       "14                     TRUE                          False   \n",
       "15  has weird double z axis                          False   \n",
       "16                      NaN                          False   \n",
       "17                      NaN                          False   \n",
       "18                      NaN                          False   \n",
       "19                      NaN                          False   \n",
       "20                     TRUE                          False   \n",
       "21                     TRUE                          False   \n",
       "22                     TRUE                          False   \n",
       "23                     TRUE                          False   \n",
       "24                     TRUE                          False   \n",
       "25                    FALSE                          False   \n",
       "26                    FALSE                          False   \n",
       "27                    FALSE                           True   \n",
       "28                     TRUE                          False   \n",
       "29                    FALSE                           True   \n",
       "30                    FALSE                          False   \n",
       "31                    FALSE                           True   \n",
       "32                     TRUE                           True   \n",
       "33                    FALSE                           True   \n",
       "34                    FALSE                           True   \n",
       "35                    FALSE                          False   \n",
       "36                    FALSE                           True   \n",
       "37                    FALSE                          False   \n",
       "\n",
       "                              raw_annotated_file_path  \\\n",
       "0   //home/jake/projects/mctv_resfiles/ants/diurna...   \n",
       "1   //home/jake/projects/mctv_resfiles/fiddlercrab...   \n",
       "2   //home/jake/projects/mctv_resfiles/fiddlercrab...   \n",
       "3   //home/jake/projects/mctv_resfiles/fiddlercrab...   \n",
       "4   //home/jake/projects/mctv_resfiles/fiddlercrab...   \n",
       "5   //home/jake/projects/mctv_resfiles/fiddlercrab...   \n",
       "6   //home/jake/projects/mctv_resfiles/fiddlercrab...   \n",
       "7   //home/jake/projects/mctv_resfiles/fiddlercrab...   \n",
       "8   //home/jake/projects/mctv_resfiles/hyperiids/h...   \n",
       "9   //home/jake/projects/mctv_resfiles/hyperiids/h...   \n",
       "10  //home/jake/projects/mctv_resfiles/hyperiids/L...   \n",
       "11  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "12  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "13  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "14  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "15  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "16  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "17  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "18  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "19  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "20  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "21  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "22  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "23  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "24  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "25  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "26  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "27  //home/jake/projects/mctv_resfiles/hyperiids/p...   \n",
       "28  //home/jake/projects/mctv_resfiles/hyperiids/p...   \n",
       "29  //home/jake/projects/mctv_resfiles/hyperiids/P...   \n",
       "30  //home/jake/projects/mctv_resfiles/psyllids/ps...   \n",
       "31  //home/jake/projects/mctv_resfiles/psyllids/ps...   \n",
       "32  //home/jake/projects/mctv_resfiles/fiddlercrab...   \n",
       "33  //home/jake/projects/mctv_resfiles/hyperiids/b...   \n",
       "34  //home/jake/projects/mctv_resfiles/hyperiids/p...   \n",
       "35  //home/jake/projects/mctv_resfiles/hyperiids/s...   \n",
       "36  //home/jake/projects/mctv_resfiles/hyperiids/s...   \n",
       "37  //home/jake/projects/mctv_resfiles/hyperiids/s...   \n",
       "\n",
       "                                          other notes  \n",
       "0   data with incorrect spacing have irregular siz...  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21                                                NaN  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                                                NaN  \n",
       "26                                                NaN  \n",
       "27                                                NaN  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30                                                NaN  \n",
       "31                                                NaN  \n",
       "32                                                NaN  \n",
       "33                                                NaN  \n",
       "34                                                NaN  \n",
       "35                                                NaN  \n",
       "36                                                NaN  \n",
       "37                                                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = pd.read_csv('raw_image_info.csv')\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view one of the label files to see where the data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//home/jake/projects/mctv_resfiles/ants/diurnal_tarsata/tarsata.mat'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.loc[0, 'raw_annotated_file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ana <HDF5 group \"/save_dat/ana\" (1 members)>\n",
      "ana/para <HDF5 group \"/save_dat/ana/para\" (11 members)>\n",
      "ana/para/allow_splitting_rows_by_distance <HDF5 dataset \"allow_splitting_rows_by_distance\": shape (1, 1), type \"<f8\">\n",
      "ana/para/distance_for_pointtext <HDF5 dataset \"distance_for_pointtext\": shape (1, 1), type \"<f8\">\n",
      "ana/para/include_non_empty <HDF5 dataset \"include_non_empty\": shape (1, 1), type \"<f8\">\n",
      "ana/para/main_marker_size <HDF5 dataset \"main_marker_size\": shape (1, 1), type \"<f8\">\n",
      "ana/para/pt_th <HDF5 dataset \"pt_th\": shape (1, 1), type \"<f8\">\n",
      "ana/para/row_th <HDF5 dataset \"row_th\": shape (1, 1), type \"<f8\">\n",
      "ana/para/spline_stiff <HDF5 dataset \"spline_stiff\": shape (1, 1), type \"<f8\">\n",
      "ana/para/spline_stiff_smooth <HDF5 dataset \"spline_stiff_smooth\": shape (1, 1), type \"<f8\">\n",
      "ana/para/spline_stiff_soft_mult <HDF5 dataset \"spline_stiff_soft_mult\": shape (1, 1), type \"<f8\">\n",
      "ana/para/spline_stiff_z_mult <HDF5 dataset \"spline_stiff_z_mult\": shape (1, 1), type \"<f8\">\n",
      "ana/para/text_size <HDF5 dataset \"text_size\": shape (1, 1), type \"<f8\">\n",
      "autosave <HDF5 group \"/save_dat/autosave\" (4 members)>\n",
      "autosave/ctr <HDF5 dataset \"ctr\": shape (1, 1), type \"<f8\">\n",
      "autosave/filectr <HDF5 dataset \"filectr\": shape (1, 1), type \"<f8\">\n",
      "autosave/howmany <HDF5 dataset \"howmany\": shape (1, 1), type \"<f8\">\n",
      "autosave/howoften <HDF5 dataset \"howoften\": shape (1, 1), type \"<f8\">\n",
      "data <HDF5 group \"/save_dat/data\" (22 members)>\n",
      "data/colid <HDF5 dataset \"colid\": shape (2,), type \"<u8\">\n",
      "data/current_m <HDF5 dataset \"current_m\": shape (4, 4), type \"<f8\">\n",
      "data/current_pad <HDF5 dataset \"current_pad\": shape (3, 1), type \"<f8\">\n",
      "data/current_rotation <HDF5 dataset \"current_rotation\": shape (1, 1), type \"<f8\">\n",
      "data/current_trim <HDF5 dataset \"current_trim\": shape (3, 1), type \"<f8\">\n",
      "data/marked <HDF5 dataset \"marked\": shape (9, 5180), type \"<f8\">\n",
      "data/rowid <HDF5 dataset \"rowid\": shape (2,), type \"<u8\">\n",
      "data/search_x_weight <HDF5 dataset \"search_x_weight\": shape (1, 1), type \"<f8\">\n",
      "data/search_y_weight <HDF5 dataset \"search_y_weight\": shape (1, 1), type \"<f8\">\n",
      "data/search_z_weight <HDF5 dataset \"search_z_weight\": shape (1, 1), type \"<f8\">\n",
      "data/shell1 <HDF5 dataset \"shell1\": shape (1, 1), type \"<f8\">\n",
      "data/shell2 <HDF5 dataset \"shell2\": shape (1, 1), type \"<f8\">\n",
      "data/store_marked <HDF5 dataset \"store_marked\": shape (9, 5180), type \"<f8\">\n",
      "data/trans_r <HDF5 dataset \"trans_r\": shape (3, 6), type \"<f8\">\n",
      "data/undo <HDF5 group \"/save_dat/data/undo\" (3 members)>\n",
      "data/undo/dat <HDF5 group \"/save_dat/data/undo/dat\" (1 members)>\n",
      "data/undo/dat/dat <HDF5 dataset \"dat\": shape (50, 1), type \"|O\">\n",
      "data/undo/ind <HDF5 dataset \"ind\": shape (1, 1), type \"<f8\">\n",
      "data/undo/op <HDF5 dataset \"op\": shape (50, 1), type \"|O\">\n",
      "data/update_row_col1 <HDF5 dataset \"update_row_col1\": shape (1, 1), type \"<f8\">\n",
      "data/update_row_col2 <HDF5 dataset \"update_row_col2\": shape (1, 1), type \"<f8\">\n",
      "data/window_current_datam <HDF5 dataset \"window_current_datam\": shape (1, 1), type \"<f8\">\n",
      "data/window_current_image_rotation <HDF5 dataset \"window_current_image_rotation\": shape (3, 1), type \"<f8\">\n",
      "data/window_current_inv_datam <HDF5 dataset \"window_current_inv_datam\": shape (1, 1), type \"<f8\">\n",
      "data/window_current_m <HDF5 dataset \"window_current_m\": shape (1, 1), type \"<f8\">\n",
      "data/window_last_inverse <HDF5 dataset \"window_last_inverse\": shape (1, 1), type \"<f8\">\n",
      "figh <HDF5 dataset \"figh\": shape (1, 1), type \"<f8\">\n",
      "figh_ana <HDF5 dataset \"figh_ana\": shape (1, 1), type \"<f8\">\n",
      "figh_fana <HDF5 dataset \"figh_fana\": shape (1, 1), type \"<f8\">\n",
      "gd <HDF5 group \"/save_dat/gd\" (23 members)>\n",
      "gd/ax4_zoom <HDF5 dataset \"ax4_zoom\": shape (1, 1), type \"<f8\">\n",
      "gd/axorder <HDF5 dataset \"axorder\": shape (4, 1), type \"<f8\">\n",
      "gd/cm_highlim <HDF5 dataset \"cm_highlim\": shape (1, 1), type \"<f8\">\n",
      "gd/cm_lowlim <HDF5 dataset \"cm_lowlim\": shape (1, 1), type \"<f8\">\n",
      "gd/cols <HDF5 dataset \"cols\": shape (3, 3), type \"<f8\">\n",
      "gd/depthsel <HDF5 dataset \"depthsel\": shape (2, 1), type \"<f8\">\n",
      "gd/imf <HDF5 dataset \"imf\": shape (1, 1), type \"<f8\">\n",
      "gd/in_row_pt_dist <HDF5 dataset \"in_row_pt_dist\": shape (1, 1), type \"<f8\">\n",
      "gd/markerfontsize <HDF5 dataset \"markerfontsize\": shape (1, 1), type \"<f8\">\n",
      "gd/markersize <HDF5 dataset \"markersize\": shape (1, 1), type \"<f8\">\n",
      "gd/out_in_val <HDF5 dataset \"out_in_val\": shape (1, 1), type \"<f8\">\n",
      "gd/plot_limit_text_numbers <HDF5 dataset \"plot_limit_text_numbers\": shape (1, 1), type \"<f8\">\n",
      "gd/plot_lines <HDF5 dataset \"plot_lines\": shape (1, 1), type \"<f8\">\n",
      "gd/plot_text_c <HDF5 dataset \"plot_text_c\": shape (1, 1), type \"|u1\">\n",
      "gd/plot_text_h <HDF5 dataset \"plot_text_h\": shape (1, 1), type \"|u1\">\n",
      "gd/point_dist_expected <HDF5 dataset \"point_dist_expected\": shape (1, 1), type \"<f8\">\n",
      "gd/pressed_col <HDF5 dataset \"pressed_col\": shape (3, 1), type \"<f8\">\n",
      "gd/rotate_orientation <HDF5 dataset \"rotate_orientation\": shape (14, 1), type \"<u2\">\n",
      "gd/select_dist <HDF5 dataset \"select_dist\": shape (1, 1), type \"<f8\">\n",
      "gd/sout_in <HDF5 dataset \"sout_in\": shape (1, 1), type \"<f8\">\n",
      "gd/trans <HDF5 group \"/save_dat/gd/trans\" (3 members)>\n",
      "gd/trans/l <HDF5 dataset \"l\": shape (6, 1), type \"|O\">\n",
      "gd/trans/r <HDF5 dataset \"r\": shape (6, 1), type \"|O\">\n",
      "gd/trans/ra <HDF5 dataset \"ra\": shape (6, 1), type \"|O\">\n",
      "gd/unpressed_col <HDF5 dataset \"unpressed_col\": shape (3, 1), type \"<f8\">\n",
      "gd/use_altfigure <HDF5 dataset \"use_altfigure\": shape (4, 1), type \"<f8\">\n",
      "rmfields <HDF5 group \"/save_dat/rmfields\" (2 members)>\n",
      "rmfields/s <HDF5 dataset \"s\": shape (4, 1), type \"|O\">\n",
      "rmfields/stack <HDF5 dataset \"stack\": shape (5, 1), type \"|O\">\n",
      "rotation_size_limit <HDF5 dataset \"rotation_size_limit\": shape (1, 1), type \"<f8\">\n",
      "rotation_size_min <HDF5 dataset \"rotation_size_min\": shape (1, 1), type \"<f8\">\n",
      "savename <HDF5 dataset \"savename\": shape (32, 1), type \"<u2\">\n",
      "stack <HDF5 group \"/save_dat/stack\" (24 members)>\n",
      "stack/autobackward <HDF5 dataset \"autobackward\": shape (1, 1), type \"<f8\">\n",
      "stack/autocentering <HDF5 dataset \"autocentering\": shape (1, 1), type \"|u1\">\n",
      "stack/autocentering_all <HDF5 dataset \"autocentering_all\": shape (1, 1), type \"|u1\">\n",
      "stack/autoforward <HDF5 dataset \"autoforward\": shape (1, 1), type \"<f8\">\n",
      "stack/cl <HDF5 dataset \"cl\": shape (3, 1), type \"<f8\">\n",
      "stack/crossh <HDF5 group \"/save_dat/stack/crossh\" (9 members)>\n",
      "stack/crossh/im1_1 <HDF5 dataset \"im1_1\": shape (1, 6), type \"<u4\">\n",
      "stack/crossh/im1_2 <HDF5 dataset \"im1_2\": shape (1, 6), type \"<u4\">\n",
      "stack/crossh/im2_1 <HDF5 dataset \"im2_1\": shape (1, 6), type \"<u4\">\n",
      "stack/crossh/im2_2 <HDF5 dataset \"im2_2\": shape (1, 6), type \"<u4\">\n",
      "stack/crossh/im3_1 <HDF5 dataset \"im3_1\": shape (1, 6), type \"<u4\">\n",
      "stack/crossh/im3_2 <HDF5 dataset \"im3_2\": shape (1, 6), type \"<u4\">\n",
      "stack/crossh/im4_1 <HDF5 dataset \"im4_1\": shape (1, 6), type \"<u4\">\n",
      "stack/crossh/im4_2 <HDF5 dataset \"im4_2\": shape (1, 6), type \"<u4\">\n",
      "stack/crossh/im4_3 <HDF5 dataset \"im4_3\": shape (1, 6), type \"<u4\">\n",
      "stack/current_rotation_string <HDF5 dataset \"current_rotation_string\": shape (2,), type \"<u8\">\n",
      "stack/datasavename <HDF5 dataset \"datasavename\": shape (2,), type \"<u8\">\n",
      "stack/fixedzoom_level <HDF5 dataset \"fixedzoom_level\": shape (1, 1), type \"<f8\">\n",
      "stack/image_format <HDF5 dataset \"image_format\": shape (5, 1), type \"<u2\">\n",
      "stack/local_interactive <HDF5 dataset \"local_interactive\": shape (1, 1), type \"<f8\">\n",
      "stack/origin <HDF5 dataset \"origin\": shape (3, 1), type \"<f8\">\n",
      "stack/rimage1 <HDF5 dataset \"rimage1\": shape (251, 251), type \"<f4\">\n",
      "stack/rimage2 <HDF5 dataset \"rimage2\": shape (251, 251), type \"<f4\">\n",
      "stack/rimage3 <HDF5 dataset \"rimage3\": shape (251, 251), type \"<f4\">\n",
      "stack/rimage_sel1 <HDF5 dataset \"rimage_sel1\": shape (251, 1), type \"<f8\">\n",
      "stack/rimage_sel2 <HDF5 dataset \"rimage_sel2\": shape (251, 1), type \"<f8\">\n",
      "stack/rimage_sel3 <HDF5 dataset \"rimage_sel3\": shape (251, 1), type \"<f8\">\n",
      "stack/rotate_interactive <HDF5 dataset \"rotate_interactive\": shape (1, 1), type \"<f8\">\n",
      "stack/rotated <HDF5 dataset \"rotated\": shape (1, 1), type \"<f8\">\n",
      "stack/savestore_cl <HDF5 dataset \"savestore_cl\": shape (3, 1), type \"<f8\">\n",
      "stack/show_all_directions <HDF5 dataset \"show_all_directions\": shape (1, 1), type \"<f8\">\n",
      "stack/start_with <HDF5 dataset \"start_with\": shape (6, 1), type \"<u2\">\n",
      "stack/view_interactive <HDF5 dataset \"view_interactive\": shape (1, 1), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(info.loc[0, 'raw_annotated_file_path'], mode='r')\n",
    "\n",
    "f['save_dat'].visititems(lambda n, o:print(n, o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5170</th>\n",
       "      <th>5171</th>\n",
       "      <th>5172</th>\n",
       "      <th>5173</th>\n",
       "      <th>5174</th>\n",
       "      <th>5175</th>\n",
       "      <th>5176</th>\n",
       "      <th>5177</th>\n",
       "      <th>5178</th>\n",
       "      <th>5179</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210.378869</td>\n",
       "      <td>208.715220</td>\n",
       "      <td>203.161893</td>\n",
       "      <td>201.773182</td>\n",
       "      <td>216.326074</td>\n",
       "      <td>211.377609</td>\n",
       "      <td>207.015189</td>\n",
       "      <td>202.492341</td>\n",
       "      <td>200.279329</td>\n",
       "      <td>199.304796</td>\n",
       "      <td>...</td>\n",
       "      <td>745.026416</td>\n",
       "      <td>746.956193</td>\n",
       "      <td>749.140737</td>\n",
       "      <td>752.587520</td>\n",
       "      <td>755.880528</td>\n",
       "      <td>750.993639</td>\n",
       "      <td>750.950449</td>\n",
       "      <td>748.290773</td>\n",
       "      <td>750.992589</td>\n",
       "      <td>752.272633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>610.125062</td>\n",
       "      <td>608.291494</td>\n",
       "      <td>617.583415</td>\n",
       "      <td>627.088487</td>\n",
       "      <td>597.115077</td>\n",
       "      <td>601.899662</td>\n",
       "      <td>603.774637</td>\n",
       "      <td>614.244095</td>\n",
       "      <td>624.459194</td>\n",
       "      <td>633.980652</td>\n",
       "      <td>...</td>\n",
       "      <td>443.376608</td>\n",
       "      <td>430.567993</td>\n",
       "      <td>420.227072</td>\n",
       "      <td>411.458105</td>\n",
       "      <td>403.947978</td>\n",
       "      <td>401.989690</td>\n",
       "      <td>397.802645</td>\n",
       "      <td>439.233097</td>\n",
       "      <td>430.750563</td>\n",
       "      <td>421.386247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>618.403081</td>\n",
       "      <td>605.820510</td>\n",
       "      <td>597.841257</td>\n",
       "      <td>598.722290</td>\n",
       "      <td>622.821452</td>\n",
       "      <td>613.526117</td>\n",
       "      <td>597.957832</td>\n",
       "      <td>588.549029</td>\n",
       "      <td>587.718511</td>\n",
       "      <td>594.389523</td>\n",
       "      <td>...</td>\n",
       "      <td>417.117119</td>\n",
       "      <td>429.199554</td>\n",
       "      <td>438.165841</td>\n",
       "      <td>448.930036</td>\n",
       "      <td>460.621231</td>\n",
       "      <td>462.513364</td>\n",
       "      <td>472.234956</td>\n",
       "      <td>424.412174</td>\n",
       "      <td>436.990685</td>\n",
       "      <td>446.607978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 5180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0           1           2           3           4           5     \\\n",
       "0  210.378869  208.715220  203.161893  201.773182  216.326074  211.377609   \n",
       "1  610.125062  608.291494  617.583415  627.088487  597.115077  601.899662   \n",
       "2  618.403081  605.820510  597.841257  598.722290  622.821452  613.526117   \n",
       "3   11.000000   11.000000   11.000000   11.000000   12.000000   12.000000   \n",
       "4   52.000000   53.000000   54.000000   55.000000   51.000000   52.000000   \n",
       "5    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "6    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "7    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "8    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "         6           7           8           9     ...        5170  \\\n",
       "0  207.015189  202.492341  200.279329  199.304796  ...  745.026416   \n",
       "1  603.774637  614.244095  624.459194  633.980652  ...  443.376608   \n",
       "2  597.957832  588.549029  587.718511  594.389523  ...  417.117119   \n",
       "3   12.000000   12.000000   12.000000   12.000000  ...   76.000000   \n",
       "4   53.000000   54.000000   55.000000   56.000000  ...   42.000000   \n",
       "5    0.000000    0.000000    0.000000    0.000000  ...    1.000000   \n",
       "6    0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "7    0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "8    0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "\n",
       "         5171        5172        5173        5174        5175        5176  \\\n",
       "0  746.956193  749.140737  752.587520  755.880528  750.993639  750.950449   \n",
       "1  430.567993  420.227072  411.458105  403.947978  401.989690  397.802645   \n",
       "2  429.199554  438.165841  448.930036  460.621231  462.513364  472.234956   \n",
       "3   76.000000   76.000000   76.000000   76.000000   76.000000   76.000000   \n",
       "4   43.000000   44.000000   45.000000   46.000000   47.000000   48.000000   \n",
       "5    1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "6    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "7    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "8    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "         5177        5178        5179  \n",
       "0  748.290773  750.992589  752.272633  \n",
       "1  439.233097  430.750563  421.386247  \n",
       "2  424.412174  436.990685  446.607978  \n",
       "3   77.000000   77.000000   77.000000  \n",
       "4   43.000000   44.000000   45.000000  \n",
       "5    1.000000    1.000000    1.000000  \n",
       "6    0.000000    0.000000    0.000000  \n",
       "7    0.000000    0.000000    0.000000  \n",
       "8    0.000000    0.000000    0.000000  \n",
       "\n",
       "[9 rows x 5180 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(f['save_dat/data/marked']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_748838/1891607671.py:1: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dicom'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same thing with scipy in the case where the matlab file is an old type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = info.loc[2, 'raw_annotated_file_path']\n",
    "\n",
    "mat = scipy.io.loadmat(dir)\n",
    "\n",
    "file_type = mat['save_dat'][0]['stack'][0]['image_format'][0][0][0]\n",
    "classification = pd.DataFrame(mat['save_dat'][0]['data'][0][0][0][0]).iloc[:,5]\n",
    "points = pd.DataFrame(mat['save_dat'][0]['data'][0][0][0][0]).iloc[:,[2, 1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nifti'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "13914    0.0\n",
       "13915    0.0\n",
       "13916    0.0\n",
       "13917    0.0\n",
       "13918    0.0\n",
       "Name: 5, Length: 13919, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492.100525</td>\n",
       "      <td>456.952484</td>\n",
       "      <td>814.715515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>480.170630</td>\n",
       "      <td>447.510213</td>\n",
       "      <td>815.730097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503.717560</td>\n",
       "      <td>467.951080</td>\n",
       "      <td>814.715515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>502.127380</td>\n",
       "      <td>481.467499</td>\n",
       "      <td>814.715515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488.699310</td>\n",
       "      <td>472.278168</td>\n",
       "      <td>817.098267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13914</th>\n",
       "      <td>222.343597</td>\n",
       "      <td>455.246357</td>\n",
       "      <td>263.753937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13915</th>\n",
       "      <td>234.833111</td>\n",
       "      <td>454.485577</td>\n",
       "      <td>257.645381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13916</th>\n",
       "      <td>284.391574</td>\n",
       "      <td>439.530726</td>\n",
       "      <td>803.305356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13917</th>\n",
       "      <td>397.746509</td>\n",
       "      <td>222.228610</td>\n",
       "      <td>389.085456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13918</th>\n",
       "      <td>240.247288</td>\n",
       "      <td>740.072203</td>\n",
       "      <td>440.675276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13919 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                2           1           0\n",
       "0      492.100525  456.952484  814.715515\n",
       "1      480.170630  447.510213  815.730097\n",
       "2      503.717560  467.951080  814.715515\n",
       "3      502.127380  481.467499  814.715515\n",
       "4      488.699310  472.278168  817.098267\n",
       "...           ...         ...         ...\n",
       "13914  222.343597  455.246357  263.753937\n",
       "13915  234.833111  454.485577  257.645381\n",
       "13916  284.391574  439.530726  803.305356\n",
       "13917  397.746509  222.228610  389.085456\n",
       "13918  240.247288  740.072203  440.675276\n",
       "\n",
       "[13919 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the locations of the annotations in x, y and z space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5170</th>\n",
       "      <th>5171</th>\n",
       "      <th>5172</th>\n",
       "      <th>5173</th>\n",
       "      <th>5174</th>\n",
       "      <th>5175</th>\n",
       "      <th>5176</th>\n",
       "      <th>5177</th>\n",
       "      <th>5178</th>\n",
       "      <th>5179</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>618.403081</td>\n",
       "      <td>605.820510</td>\n",
       "      <td>597.841257</td>\n",
       "      <td>598.722290</td>\n",
       "      <td>622.821452</td>\n",
       "      <td>613.526117</td>\n",
       "      <td>597.957832</td>\n",
       "      <td>588.549029</td>\n",
       "      <td>587.718511</td>\n",
       "      <td>594.389523</td>\n",
       "      <td>...</td>\n",
       "      <td>417.117119</td>\n",
       "      <td>429.199554</td>\n",
       "      <td>438.165841</td>\n",
       "      <td>448.930036</td>\n",
       "      <td>460.621231</td>\n",
       "      <td>462.513364</td>\n",
       "      <td>472.234956</td>\n",
       "      <td>424.412174</td>\n",
       "      <td>436.990685</td>\n",
       "      <td>446.607978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>610.125062</td>\n",
       "      <td>608.291494</td>\n",
       "      <td>617.583415</td>\n",
       "      <td>627.088487</td>\n",
       "      <td>597.115077</td>\n",
       "      <td>601.899662</td>\n",
       "      <td>603.774637</td>\n",
       "      <td>614.244095</td>\n",
       "      <td>624.459194</td>\n",
       "      <td>633.980652</td>\n",
       "      <td>...</td>\n",
       "      <td>443.376608</td>\n",
       "      <td>430.567993</td>\n",
       "      <td>420.227072</td>\n",
       "      <td>411.458105</td>\n",
       "      <td>403.947978</td>\n",
       "      <td>401.989690</td>\n",
       "      <td>397.802645</td>\n",
       "      <td>439.233097</td>\n",
       "      <td>430.750563</td>\n",
       "      <td>421.386247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210.378869</td>\n",
       "      <td>208.715220</td>\n",
       "      <td>203.161893</td>\n",
       "      <td>201.773182</td>\n",
       "      <td>216.326074</td>\n",
       "      <td>211.377609</td>\n",
       "      <td>207.015189</td>\n",
       "      <td>202.492341</td>\n",
       "      <td>200.279329</td>\n",
       "      <td>199.304796</td>\n",
       "      <td>...</td>\n",
       "      <td>745.026416</td>\n",
       "      <td>746.956193</td>\n",
       "      <td>749.140737</td>\n",
       "      <td>752.587520</td>\n",
       "      <td>755.880528</td>\n",
       "      <td>750.993639</td>\n",
       "      <td>750.950449</td>\n",
       "      <td>748.290773</td>\n",
       "      <td>750.992589</td>\n",
       "      <td>752.272633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0           1           2           3           4           5     \\\n",
       "2  618.403081  605.820510  597.841257  598.722290  622.821452  613.526117   \n",
       "1  610.125062  608.291494  617.583415  627.088487  597.115077  601.899662   \n",
       "0  210.378869  208.715220  203.161893  201.773182  216.326074  211.377609   \n",
       "\n",
       "         6           7           8           9     ...        5170  \\\n",
       "2  597.957832  588.549029  587.718511  594.389523  ...  417.117119   \n",
       "1  603.774637  614.244095  624.459194  633.980652  ...  443.376608   \n",
       "0  207.015189  202.492341  200.279329  199.304796  ...  745.026416   \n",
       "\n",
       "         5171        5172        5173        5174        5175        5176  \\\n",
       "2  429.199554  438.165841  448.930036  460.621231  462.513364  472.234956   \n",
       "1  430.567993  420.227072  411.458105  403.947978  401.989690  397.802645   \n",
       "0  746.956193  749.140737  752.587520  755.880528  750.993639  750.950449   \n",
       "\n",
       "         5177        5178        5179  \n",
       "2  424.412174  436.990685  446.607978  \n",
       "1  439.233097  430.750563  421.386247  \n",
       "0  748.290773  750.992589  752.272633  \n",
       "\n",
       "[3 rows x 5180 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(f['save_dat']['data']['marked'])).iloc[[2, 1, 0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the category associated with the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "       ... \n",
       "5175    1.0\n",
       "5176    1.0\n",
       "5177    1.0\n",
       "5178    1.0\n",
       "5179    1.0\n",
       "Name: 5, Length: 5180, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(f['save_dat']['data']['marked'])).iloc[5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's set up some helper functions to generate annotated prediction volumes for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def _bool_3d_filter(array, indices, buffer=3):\n",
    "    # TODO: do i need to subtract 1 to these because of differences in matlab and python indexing?\n",
    "    for i in range(len(indices[0])):\n",
    "        ind = (indices[0][i], indices[1][i], indices[2][i])\n",
    "        x_min = max(ind[0] - buffer, 0)\n",
    "        x_max = min(ind[0] + buffer, array.shape[1])\n",
    "        y_min = max(ind[1] - buffer, 0)\n",
    "        y_max = min(ind[1] + buffer, array.shape[2])\n",
    "        z_min = max(ind[2] - buffer, 0)\n",
    "        z_max = min(ind[2] + buffer, array.shape[3])\n",
    "        \n",
    "        array[0, x_min:x_max, y_min:y_max, z_min:z_max] = 1\n",
    "    \n",
    "    return array\n",
    "\n",
    "\n",
    "def nn(x):\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, algorithm='auto', metric='euclidean').fit(x)\n",
    "    distances, indices = nbrs.kneighbors(x)\n",
    "    return distances, indices\n",
    "\n",
    "\n",
    "def _load_point_data(dir, swap_xy):\n",
    "#    print('loading point data from .mat files...')\n",
    "    # load classifications\n",
    "    if h5py.is_hdf5(dir):\n",
    "        f = h5py.File(dir, mode='r')\n",
    "        classification = pd.DataFrame(np.array(f['save_dat']['data']['marked'])).iloc[5, :]\n",
    "        file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
    "#        print(f'Detected {file_type} file type')\n",
    "        if swap_xy:\n",
    "            points = pd.DataFrame(np.array(f['save_dat']['data']['marked'])).iloc[[2, 0, 1], :].T\n",
    "        else:\n",
    "            points = pd.DataFrame(np.array(f['save_dat']['data']['marked'])).iloc[[2, 1, 0], :].T\n",
    "    else:\n",
    "        mat = scipy.io.loadmat(dir)\n",
    "        classification = pd.DataFrame(mat['save_dat'][0]['data'][0][0][0][0]).iloc[:,5]\n",
    "        file_type = mat['save_dat'][0]['stack'][0]['image_format'][0][0][0]\n",
    "#        print(f'Detected {file_type} file type')\n",
    "        if swap_xy:\n",
    "            points = pd.DataFrame(mat['save_dat'][0]['data'][0][0][0][0]).iloc[:,[2, 0, 1]]\n",
    "        else:\n",
    "            points = pd.DataFrame(mat['save_dat'][0]['data'][0][0][0][0]).iloc[:,[2, 1, 0]]\n",
    "    \n",
    "    points.columns = ['x', 'y', 'z']\n",
    "\n",
    "\n",
    "    # convert back to numpy array and round to nearest voxel\n",
    "    points = np.array(points)\n",
    "    points = np.round(points).astype(int)\n",
    "\n",
    "    # get corneas and rhabdom locations with x, y and z data\n",
    "    cornea_indx = (classification == 0) | (classification == 2)\n",
    "    rhabdom_indx = (classification == 1) | (classification == 3)\n",
    "    cornea_locations = points[cornea_indx, :]\n",
    "    rhabdom_locations = points[rhabdom_indx, :]\n",
    "\n",
    "    return cornea_locations, rhabdom_locations\n",
    "\n",
    "def apply_gaussian_kernel(array, indices, halfkernlen):\n",
    "    # generate kernel\n",
    "    kernel = gkern(l=1+(halfkernlen*2), sig=1.)\n",
    "    \n",
    "    for i in range(len(indices[0])):\n",
    "        # find indices\n",
    "        ind = (indices[0][i], indices[1][i], indices[2][i])\n",
    "        x_min = max(ind[0] - halfkernlen, 0)\n",
    "        x_max = min(ind[0] + halfkernlen, array.shape[1])\n",
    "        y_min = max(ind[1] - halfkernlen, 0)\n",
    "        y_max = min(ind[1] + halfkernlen, array.shape[2])\n",
    "        z_min = max(ind[2] - halfkernlen, 0)\n",
    "        z_max = min(ind[2] + halfkernlen, array.shape[3])\n",
    "        \n",
    "        # apply kernel to location of indices\n",
    "        array[0, x_min:x_max, y_min:y_max, z_min:z_max] = kernel\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(kernel)\n",
    "        plt.pause(1)\n",
    "        plt.imshow(array)\n",
    "        plt.pause(1)\n",
    "    \n",
    "    return array\n",
    "\n",
    "def gkern(l=5, sig=1.):\n",
    "    \"\"\"\\\n",
    "    creates gaussian kernel with side length `l` and a sigma of `sig`\n",
    "    \"\"\"\n",
    "    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def _point_to_segmentation_vol(image, cornea_locations, rhabdom_locations, flipY):\n",
    "    print('converting point data to segmentation volume...')\n",
    "    # create empty matrix the size of original data\n",
    "    print('creating an empty image')\n",
    "    empty = image.copy().astype('bool_')\n",
    "    empty[:, :, :] = 0\n",
    "    \n",
    "    print('copying empty images')\n",
    "    corneas = empty.copy()\n",
    "    rhabdoms = empty.copy()\n",
    "    \n",
    "    print('assigning positions of corneas and rhabdoms with buffer')\n",
    "    \n",
    "#     print('assigning positions of corneas and rhabdoms')\n",
    "#     corneas[\n",
    "#         0,\n",
    "#         cornea_locations[:, 2],\n",
    "#         cornea_locations[:, 1],\n",
    "#         cornea_locations[:, 0]\n",
    "#     ] = 1\n",
    "#     rhabdoms[\n",
    "#         0,\n",
    "#         rhabdom_locations[:, 2],\n",
    "#         rhabdom_locations[:, 1],\n",
    "#         rhabdom_locations[:, 0]\n",
    "#     ] = 1\n",
    "    \n",
    "#     # now use a maximum filter to make points a slightly larger areak\n",
    "#     # note, that maximum filter makes predictions a cube without rounded edges\n",
    "#     # a gaussian filter may be more appropriate\n",
    "#     print('running maximum filter')\n",
    "#     corneas = maximum_filter(corneas, size=3)\n",
    "#     rhabdoms = maximum_filter(rhabdoms, size=3)\n",
    "\n",
    "#    # set buffer size to be relative to image spacing\n",
    "#    # work out average distance between corneas\n",
    "#    cornea_distances = nn(cornea_locations)\n",
    "#    av_cornea_distance = np.mean(pd.DataFrame(cornea_distances[0]).iloc[:, 1])\n",
    "#    cornea_buff = np.floor(av_cornea_distance * 0.3).astype(int)\n",
    "#\n",
    "#    # now work average distance between rhabdoms\n",
    "#    rhabdom_distances = nn(rhabdom_locations)\n",
    "#    av_rhabdom_distance = np.mean(pd.DataFrame(rhabdom_distances[0]).iloc[:, 1])\n",
    "#    rhabdom_buff = np.floor(av_rhabdom_distance * 0.3).astype(int)\n",
    "#    \n",
    "#    print(f'cornea buffer {cornea_buff}')\n",
    "#    print(f'rhabdom buffer {rhabdom_buff}')\n",
    "#    \n",
    "#    corneas = _bool_3d_filter(\n",
    "#        corneas,\n",
    "#        (\n",
    "#            cornea_locations[:, 2],\n",
    "#            cornea_locations[:, 1],\n",
    "#            cornea_locations[:, 0]\n",
    "#        ),\n",
    "#        buffer=cornea_buff\n",
    "#    )\n",
    "#    \n",
    "#    rhabdoms = _bool_3d_filter(\n",
    "#        rhabdoms,\n",
    "#        (\n",
    "#            rhabdom_locations[:, 2],\n",
    "#            rhabdom_locations[:, 1],\n",
    "#            rhabdom_locations[:, 0]\n",
    "#        ),\n",
    "#        buffer=rhabdom_buff\n",
    "#    )\n",
    "    \n",
    "    corneas = apply_gaussian_kernel(\n",
    "        corneas,\n",
    "        (\n",
    "            cornea_locations[:, 2],\n",
    "            cornea_locations[:, 1],\n",
    "            cornea_locations[:, 0]\n",
    "        ),\n",
    "        7\n",
    "    )\n",
    "    \n",
    "    rhabdoms = apply_gaussian_kernel(\n",
    "        rhabdoms,\n",
    "        (\n",
    "            rhabdom_locations[:, 2],\n",
    "            rhabdom_locations[:, 1],\n",
    "            rhabdom_locations[:, 0]\n",
    "        ),\n",
    "        7\n",
    "    )\n",
    "    \n",
    "    # now merge both into a single prediction volume\n",
    "    # 0 = nothing\n",
    "    # 1 = cornea\n",
    "    # 2 = rhabdom\n",
    "    print('merging cornea and rhabdom images into single volume')\n",
    "    \n",
    "    import pdb; pdb.set_trace()\n",
    "\n",
    "    prediction = empty.astype(np.int16)\n",
    "    prediction[corneas] = 1\n",
    "    prediction[rhabdoms] = 2\n",
    "\n",
    "    if flipY:\n",
    "        print('Flipping Y because file was annotated with dicom')\n",
    "        prediction = np.flip(prediction, 2).copy()\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "\n",
    "def calculate_av_cornea_distance(dir, swap_xy=False):\n",
    "    cornea_locations, rhabdom_locations = _load_point_data(dir, swap_xy)\n",
    "    # work out average distance between corneas\n",
    "    cornea_distances = nn(cornea_locations)\n",
    "    av_cornea_distance = np.mean(pd.DataFrame(cornea_distances[0]).iloc[:, 1])\n",
    "    return av_cornea_distance\n",
    "    \n",
    "\n",
    "def create_annotated_volumes(dir, image, swap_xy, flip_y, img_resample_perc):\n",
    "    cornea_locations, rhabdom_locations = _load_point_data(dir, swap_xy)\n",
    "    # apply the same resampling that was made to the image, so that \n",
    "    # annotated features line up correctly\n",
    "    cornea_locations = int(round(cornea_locations / img_resample_perc))\n",
    "    rhabdom_locations = int(round(rhabdom_locations / img_resample_perc))\n",
    "    annotated_vol = _point_to_segmentation_vol(\n",
    "        image,\n",
    "        cornea_locations,\n",
    "        rhabdom_locations,\n",
    "        flip_y\n",
    "    )\n",
    "    print('done.')\n",
    "    return annotated_vol\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the input images to the network to be rescaled so corneas and rhabdoms are roughly the same size for all animals. That way, the network can learn the basic shape of the cornea or rhabdom while minimising the effect of different sizes between animals. \n",
    "\n",
    "To do this, I scale the images so that the average interommatidial distance is 20 voxels.\n",
    "\n",
    "This follows the below formula:\n",
    "\n",
    "$\n",
    "Rescale Percent = \\frac{Mean Distance Between Corneas}{20}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average cornea distance across all images was 31.35011018808365 with a SE of 3.5406130996662806\n",
      "[10.783240550181521, 7.315245258241414, 11.11653254539684, 12.520171910451982, 7.97367812437899, 8.566901473072177, 18.5485769528827, 19.97195073229132, 25.901299596819495, 26.5149596092691, 21.747966324525958, 41.20789533844307, 77.50971149554603, 36.517652941607224, 36.394002297893024, 44.7548356229362, 57.42033429102824, 55.86283123174013, 28.826595636354842, 67.15886184148857, 61.704902291691226, 72.64687216998699, 79.69892989162773, 53.8739033483369, 62.54235710666497, 22.798974021439328, 20.429901811551858, 21.786383869015072, 31.99503012820906, 12.797140314165448, 9.680270156807332, 10.392084747104066, 8.41418086715663, 24.57083821462901, 12.797140314165448, 10.973319322330399, 29.618899810534582, 27.969814987213766]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n",
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "n_rows = info.shape[0]\n",
    "\n",
    "out_label_dir = './dataset/labels/'\n",
    "out_image_dir = './dataset/images/'\n",
    "\n",
    "i = 0\n",
    "\n",
    "av_cornea_distances = []\n",
    "for i in range(n_rows):\n",
    "    label = info.loc[i, 'raw_annotated_file_path']\n",
    "    av_cornea_distances.append(calculate_av_cornea_distance(label))\n",
    "\n",
    "print(f'The average cornea distance across all images was {np.mean(av_cornea_distances)} with a SE of {np.std(av_cornea_distances, ddof=1) / np.sqrt(np.size(av_cornea_distances))}')\n",
    "print(av_cornea_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting conversion of diurnal_tarsata\n",
      "Resampling the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image new spacing (0.539162027509076, 0.539162027509076, 0.539162027509076)\n",
      "converting point data to segmentation volume...\n",
      "creating an empty image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_748838/4156163909.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  file_type = f['save_dat']['stack']['image_format'].value.tobytes()[::2].decode()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying empty images\n",
      "assigning positions of corneas and rhabdoms with buffer\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_748838/4022379191.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         ann = tio.LabelMap(\n\u001b[0;32m---> 56\u001b[0;31m             tensor=create_annotated_volumes(\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_748838/4156163909.py\u001b[0m in \u001b[0;36mcreate_annotated_volumes\u001b[0;34m(dir, image, swap_xy, flip_y, img_resample_perc)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mcornea_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcornea_locations\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mimg_resample_perc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mrhabdom_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrhabdom_locations\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mimg_resample_perc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     annotated_vol = _point_to_segmentation_vol(\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mcornea_locations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_748838/4156163909.py\u001b[0m in \u001b[0;36m_point_to_segmentation_vol\u001b[0;34m(image, cornea_locations, rhabdom_locations, flipY)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;31m#    )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     corneas = apply_gaussian_kernel(\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mcorneas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         (\n",
      "\u001b[0;32m/tmp/ipykernel_748838/4156163909.py\u001b[0m in \u001b[0;36mapply_gaussian_kernel\u001b[0;34m(array, indices, halfkernlen)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# apply kernel to location of indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz_max\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "n_rows = info.shape[0]\n",
    "\n",
    "out_label_dir = './dataset/labels/'\n",
    "out_image_dir = './dataset/images/'\n",
    "\n",
    "plot = False\n",
    "\n",
    "\n",
    "for i in range(n_rows):\n",
    "    img = info.loc[i, 'image_file_path']\n",
    "    label = info.loc[i, 'raw_annotated_file_path']\n",
    "    # swap_xy = info.loc[i, 'swap_xy']\n",
    "    # flip_y = info.loc[i, 'flip_y']\n",
    "\n",
    "    p = Path(img)\n",
    "    filename = p.stem\n",
    "    out_path = out_label_dir + filename + '.nii'\n",
    "    image_out_path = out_image_dir + filename + '.nii'\n",
    "\n",
    "    if os.path.isdir(img):\n",
    "        swap_xy = True\n",
    "        flip_y = False\n",
    "        convert_to_nifti = True\n",
    "    else:\n",
    "        swap_xy = False\n",
    "        flip_y = False\n",
    "        convert_to_nifti = False\n",
    "    \n",
    "    if not os.path.isfile(out_path) or not os.path.isfile(image_out_path):\n",
    "        print('starting conversion of ' + filename)\n",
    "        transform = tio.ToCanonical()\n",
    "        \n",
    "        img = tio.ScalarImage(\n",
    "            img,\n",
    "            # set image spacing to be 1mm = 1 voxel, so I can resample at the voxel level\n",
    "            spacing = (1.0, 1.0, 1.0)\n",
    "        )\n",
    "        \n",
    "        # resample the image and the annotation\n",
    "        print('Resampling the image')\n",
    "        \n",
    "        old_img_shape = img.shape\n",
    "        \n",
    "        # now resample so there are at least 20 voxels between the average distance between corneas\n",
    "        resample_percentage = calculate_av_cornea_distance(label) / 20\n",
    "        transform = tio.Resample(resample_percentage)\n",
    "        img = transform(img)\n",
    "        print(f'Image new spacing {img.spacing}')\n",
    "        \n",
    "        new_img_shape = img.shape\n",
    "\n",
    "        ann = tio.LabelMap(\n",
    "            tensor=create_annotated_volumes(\n",
    "                label,\n",
    "                img.data.numpy(),\n",
    "                swap_xy,\n",
    "                flip_y,\n",
    "                img_resample_perc=resample_percentage\n",
    "            ),\n",
    "            affine=img.affine,\n",
    "            orientation=img.orientation,\n",
    "            spacing=img.spacing\n",
    "        )\n",
    "        \n",
    "        import pdb; pdb.set_trace()\n",
    "        assert ann.shape == img.shape, 'Annotation and image shape mismatch'\n",
    "\n",
    "        # convert to uint16 to save on space\n",
    "        img.set_data(img.data.numpy().astype(np.uint16))\n",
    "        ann.set_data(ann.data.numpy().astype(np.uint16))\n",
    "        \n",
    "        \n",
    "        if plot:\n",
    "            viewer = napari.Viewer()\n",
    "            viewer.dims.ndisplay = 3 # toggle 3 dimensional view\n",
    "            viewer.add_image(img.data.numpy())\n",
    "            viewer.add_image(ann.data.numpy())\n",
    "\n",
    "        # now save the label/annotation\n",
    "        if convert_to_nifti and not os.path.isfile(image_out_path):\n",
    "            print('saving image to ' + image_out_path)\n",
    "            img.save(image_out_path)\n",
    "        \n",
    "        print('saving label to ' + out_path)\n",
    "        ann.save(out_path)\n",
    "    else:\n",
    "        print(out_path + ' has already been created, so skipping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have our raw labels and images, let's move to step 03"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f726fa9e3d96265230c4503e543f5c3f73ae5ded033c480caee9e2a2a13a4b04"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
