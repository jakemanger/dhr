{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "import torch\n",
    "import torchio as tio\n",
    "from torch.utils.data import DataLoader\n",
    "import scipy.io\n",
    "from scipy.ndimage import maximum_filter\n",
    "import pandas as pb\n",
    "import numpy as np\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have volumes of micro-ct data that we are trying to label. However, the labels we currently have are 3d point locations, which isn't a format that our deep learning model can link spatially to our ct data. \n",
    "\n",
    "We want to convert these 3d point locations into a new \"prediction volume\". This is what we want our deep learning model to end up producing. It is also a format that our deep learning model can read, link spatially to our data and produce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first set up some helper functions to generate annotated prediction volumes for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_point_data(dir):\n",
    "    print('loading point data from .mat files...')\n",
    "    # load classifications\n",
    "    mat = scipy.io.loadmat(dir)\n",
    "    classification = pb.DataFrame(\n",
    "        mat['save_dat'][0]['data'][0][0][0][0]).iloc[:, 5]\n",
    "    points = pb.DataFrame(\n",
    "        mat['save_dat'][0]['data'][0][0][0][0]).iloc[:, [2, 1, 0]]\n",
    "    points.columns = ['x', 'y', 'z']\n",
    "    # convert back to numpy array and round to nearest voxel\n",
    "    points = np.array(points)\n",
    "    points = np.round(points).astype(int)\n",
    "    # get corneas and rhabdom locations with x, y and z data\n",
    "    cornea_indx = (classification == 0) | (classification == 2)\n",
    "    rhabdom_indx = (classification == 1) | (classification == 3)\n",
    "    cornea_locations = points[cornea_indx, :]\n",
    "    rhabdom_locations = points[rhabdom_indx, :]\n",
    "\n",
    "    return cornea_locations, rhabdom_locations\n",
    "\n",
    "def _point_to_segmentation_vol(image, cornea_locations, rhabdom_locations):\n",
    "    print('converting point data to segmentation volume...')\n",
    "    # create empty matrix the size of original data\n",
    "    empty = image.copy()\n",
    "    empty[:, :, :] = 0\n",
    "    \n",
    "    corneas = empty.copy()\n",
    "    rhabdoms = empty.copy()\n",
    "    \n",
    "    corneas[\n",
    "        0,\n",
    "        cornea_locations[:, 2],\n",
    "        cornea_locations[:, 1],\n",
    "        cornea_locations[:, 0]\n",
    "    ] = 1\n",
    "    rhabdoms[\n",
    "        0,\n",
    "        rhabdom_locations[:, 2],\n",
    "        rhabdom_locations[:, 1],\n",
    "        rhabdom_locations[:, 0]\n",
    "    ] = 1\n",
    "    \n",
    "    # now use a maximum filter to make points a slightly larger area\n",
    "    # note, that maximum filter makes predictions a cube without rounded edges\n",
    "    corneas = maximum_filter(corneas, size=15)\n",
    "    rhabdoms = maximum_filter(rhabdoms, size=15)\n",
    "\n",
    "    # now merge both into a single prediction volume\n",
    "    # 0 = nothing\n",
    "    # 1 = cornea\n",
    "    # 2 = rhabdom\n",
    "    prediction = empty\n",
    "    prediction[corneas > 0] = 1\n",
    "    prediction[rhabdoms > 0] = 2\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def create_annotated_volumes(dir, image):\n",
    "    cornea_locations, rhabdom_locations = _load_point_data(dir)\n",
    "    annotated_vol = _point_to_segmentation_vol(\n",
    "        image,\n",
    "        cornea_locations,\n",
    "        rhabdom_locations\n",
    "    )\n",
    "    print('done.')\n",
    "    return annotated_vol\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load our mct volumes and point data to make segmentation labels for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 'P_crassipes_FEG191022_077A'\n",
    "# id = 'flammula_20180307'\n",
    "transform = tio.ToCanonical()\n",
    "img = tio.ScalarImage(\n",
    "    'data/'+ id + '/' + id + '_image.nii.gz'\n",
    ")\n",
    "ann = tio.LabelMap(\n",
    "    tensor=create_annotated_volumes(\n",
    "        'data/'+ id + '/' + id + '.mat',\n",
    "        img.data.numpy()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "  viewer = napari.Viewer()\n",
    "  viewer.dims.ndisplay = 3 # toggle 3 dimensional view\n",
    "  viewer.add_image(img.data.numpy())\n",
    "  viewer.add_image(ann.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check that the affine matrices are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a plot to make sure everything looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = tio.Subject(\n",
    "    mct=img,\n",
    "    labels=ann,\n",
    "    id=id\n",
    ")\n",
    "subject.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've generated our labels, let's save them to disk so they can be loaded by our model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.save('data/'+ id + '/' + id + '_label.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load this data quickly during training and testing. This can be done with the approach below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tio.ScalarImage(\n",
    "    'data/'+ id + '/' + id + '_image.nii'\n",
    ")\n",
    "ann = tio.LabelMap(\n",
    "    'data/'+ id + '/' + id + '_label.nii.gz',\n",
    "    affine=img.affine\n",
    ")\n",
    "subject = tio.Subject(\n",
    "    mct=img,\n",
    "    labels=ann,\n",
    "    id=id\n",
    ")\n",
    "subject.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
