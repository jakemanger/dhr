{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "323bc225-c317-4fc6-be25-e5214ad82037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_radiologist.actions import locate_peaks, init_data\n",
    "from deep_radiologist.data_loading import _load_point_data\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import napari\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d24ede48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_acc_metrics(self, y_hat, y, k=3):\n",
    "#         \"\"\"Calculates accuracy metrics for a set of predicted and ground truth coordinates.\n",
    "\n",
    "#         Is a true positive if the distance between the predicted and closest ground truth coordinate\n",
    "#         is less than the correct_prediction_distance config parameter and that ground truth coordinate\n",
    "#         doesn't already have a better matching prediction (tested up to k closest matches). Is a false\n",
    "#         positive if the distance is greater than the correct_prediction_distance parameter or it\n",
    "#         already has a closer true positive. Is a false negative if the ground truth does not have a\n",
    "#         corresponding true positive.\n",
    "\n",
    "#         Args:\n",
    "#             y_hat (np.ndarray): predicted coordinates\n",
    "#             y (np.ndarray): ground truth coordinates\n",
    "\n",
    "#         Returns:\n",
    "#             tp (float): true positives\n",
    "#             fp (float): false positives\n",
    "#             fn (float): false negatives\n",
    "#             loc_errs (np.ndarray): location errors\n",
    "#         \"\"\"\n",
    "\n",
    "#         correct_prediction_distance = 15\n",
    "\n",
    "#         tree = spatial.cKDTree(y_hat)\n",
    "#         closest_dists, closest_nbrs = tree.query(y, k=k)\n",
    "\n",
    "#         y_match = list()\n",
    "#         y_hat_match = list()\n",
    "#         dists = list()\n",
    "\n",
    "#         for i in range(k):\n",
    "#             nbrs_k = closest_nbrs[:, i]\n",
    "#             dists_k = closest_dists[:, i]\n",
    "\n",
    "#             # sort by closest distance\n",
    "#             sort_idx = np.argsort(dists_k)\n",
    "#             nbrs_k = nbrs_k[sort_idx]\n",
    "#             dists_k = dists_k[sort_idx]\n",
    "\n",
    "#             for j in range(len(nbrs_k)):\n",
    "#                 if j not in y_hat_match and y[j, i] not in y_match:\n",
    "#                     y_hat_match.append(j)\n",
    "#                     y_match.append(y[j, i])\n",
    "#                     dists.append(dists_k[j])\n",
    "\n",
    "#         dists = np.array(dists)\n",
    "\n",
    "#         tp = len(dists[dists < correct_prediction_distance])\n",
    "#         fp = len(y_hat) - tp\n",
    "#         fn = len(y) - tp\n",
    "\n",
    "#         loc_errors = dists[dists < correct_prediction_distance]\n",
    "\n",
    "#         if len(loc_errors) == 0:\n",
    "#             loc_errors = np.array([0])\n",
    "\n",
    "#         fp_prediction = y_\n",
    "\n",
    "#         things_to_plot = [y, fp_prediction, fn_groundtruth, tp_groundtruth, tp_prediction]\n",
    "\n",
    "#         return tp, fp, fn, loc_errors, things_to_plot\n",
    "\n",
    "# def evaluate(x, y, y_hat, plot=True):\n",
    "#     mct = tio.ScalarImage(x)\n",
    "#     prediction = tio.ScalarImage(y_hat)\n",
    "#     viewer = napari.view_image(mct.to_numpy(), name=\"mct\")\n",
    "#     viewer.add_image(prediction.to_numpy(), name=\"prediction\")\n",
    "\n",
    "\n",
    "\n",
    "def get_acc_metrics(y_hat, y):\n",
    "    \"\"\"Calculates accuracy metrics for a set of predicted and ground truth coordinates.\n",
    "\n",
    "    Is a true positive if the distance between the predicted and closest ground truth coordinate\n",
    "    is less than the correct_prediction_distance config parameter. Is a false positive if the \n",
    "    distance is greater than the correct_prediction_distance parameter or it already has a closer\n",
    "    true positive. Is a false negative if the ground truth does not have a corresponding true\n",
    "    positive.\n",
    "\n",
    "    Args:\n",
    "        y_hat (np.ndarray): predicted coordinates\n",
    "        y (np.ndarray): ground truth coordinates\n",
    "\n",
    "    Returns:\n",
    "        tp (float): true positives\n",
    "        fp (float): false positives\n",
    "        fn (float): false negatives\n",
    "        loc_errs (np.ndarray): location errors\n",
    "    \"\"\"\n",
    "\n",
    "    tree = spatial.cKDTree(y)\n",
    "    closest_dists, closest_nbrs = tree.query(y_hat, k=1)\n",
    "\n",
    "    # if predictions are within distance of the same point, only keep the first one\n",
    "    # this is to avoid repeated counting of true positives that are actually false positives\n",
    "    # it doesn't matter which one is closer in this case, as we are just making a count\n",
    "    removed_dup_indx = np.unique(closest_nbrs, return_index=True)[1]\n",
    "    mask = np.zeros(closest_nbrs.shape, dtype='bool')\n",
    "    mask[removed_dup_indx] = True\n",
    "\n",
    "    true_positive = (closest_dists <= 5) & mask\n",
    "\n",
    "    tp = len(true_positive[true_positive])\n",
    "    fp = len(true_positive[~true_positive])\n",
    "    fn = y.a[0] - tp\n",
    "    loc_errors = closest_dists[true_positive]\n",
    "\n",
    "    if len(loc_errors) == 0:\n",
    "        loc_errors = np.array([0])\n",
    "\n",
    "    tp_groundtruth = closest_nbrs[true_positive]\n",
    "    fn_mask = np.ones(y.shape[0], dtype='bool')\n",
    "    fn_mask[tp_groundtruth] = False\n",
    "\n",
    "    all_ground_truth = y\n",
    "    fp_prediction = y_hat[~true_positive]\n",
    "    fn_to_plot = y[fn_mask]\n",
    "    tp_prediction = y_hat[true_positive]\n",
    "\n",
    "    things_to_plot = [all_ground_truth, fp_prediction, fn_to_plot, tp_prediction]\n",
    "\n",
    "    print(f'True positives: {tp}, False positives: {fp}, False negatives: {fn}, N Real values: {y.shape[0]}, N Predicted values: {y_hat.shape[0]}')\n",
    "    print(f'Percent correctly predicted {tp / y.shape[0] * 100}%')\n",
    "    print(f'Mean Localisation error: {loc_errors.mean()}')\n",
    "    print(f'SD Localisation error: {loc_errors.std()}')\n",
    "\n",
    "    return tp, fp, fn, loc_errors, things_to_plot\n",
    "\n",
    "def evaluate(x, y, y_hat, config, plot=True):\n",
    "    mct = tio.ScalarImage(x)\n",
    "    prediction = tio.ScalarImage(y_hat)\n",
    "\n",
    "    with open(config, \"r\") as f:\n",
    "        config = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "    data = init_data(config, run_internal_setup_func=False)\n",
    "    preprocess = data.get_preprocessing_transform()\n",
    "\n",
    "    print('Preprocessing volume for plotting')\n",
    "    mct = preprocess(mct)\n",
    "\n",
    "    prediction_locations = locate_peaks(\n",
    "        y_hat,\n",
    "        save=False,\n",
    "        plot=False,\n",
    "        peak_min_val=0.5,\n",
    "    )\n",
    "    prediction_locations = np.array(prediction_locations).T\n",
    "\n",
    "    ground_truth_locations=np.loadtxt(\n",
    "        y,\n",
    "        delimiter=',',\n",
    "        dtype=float\n",
    "    ).astype(int).T\n",
    "    \n",
    "    # flip axis 0 and 1\n",
    "    ground_truth_locations[:,0] = mct.shape[1] - ground_truth_locations[:,0]\n",
    "    ground_truth_locations[:,1] = mct.shape[2] - ground_truth_locations[:,1]\n",
    "\n",
    "    print('ground truths:')\n",
    "    print(ground_truth_locations)\n",
    "    print('predictions:')\n",
    "    print(prediction_locations)\n",
    "\n",
    "    tp, fp, fn, loc_errors, things_to_plot = get_acc_metrics(prediction_locations, ground_truth_locations)\n",
    "\n",
    "    viewer = napari.view_points(things_to_plot[0], name='all ground truth', size=6, face_color='pink')\n",
    "    viewer.add_image(mct.numpy(), name=\"x\")\n",
    "    viewer.add_image(prediction.numpy(), name=\"prediction\")\n",
    "    viewer.add_points(things_to_plot[1], name='fp prediction', size=6, face_color='red')\n",
    "    viewer.add_points(things_to_plot[2], name='fn', size=6, face_color='yellow')\n",
    "    viewer.add_points(things_to_plot[3], name='tp prediction', size=6, face_color='green')\n",
    "\n",
    "    return tp, fp, fn, loc_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a24583",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Fiddler crab corneas\n",
    "\n",
    "Image 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab4c898",
   "metadata": {},
   "source": [
    "Image 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f90dd396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchIO version: 0.18.88\n",
      "Preprocessing volume for plotting\n",
      "Locating peaks...\n",
      "ground truths:\n",
      "[[553 510 119 ... 580 585 588]\n",
      " [254 207 425 ... 451 441 432]\n",
      " [649 608  16 ... 205 207 207]]\n",
      "predictions:\n",
      "[[ 17.14516129  16.98275862  16.58536585 ... 645.03030303 644.92592593\n",
      "  644.75      ]\n",
      " [316.64516129 323.82758621 327.87804878 ... 341.84848485 345.\n",
      "  348.1875    ]\n",
      " [424.98387097 435.62068966 423.51219512 ... 492.63636364 481.33333333\n",
      "  450.3125    ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x must consist of vectors of length 8131 but has shape (3, 2421)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output/flammula_20190925_male_left-image.logs_fiddlercrab_corneas_lightning_logs_version_26_checkpoints_last_prediction.nii\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./configs/fiddlercrab_corneas.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 165\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(x, y, y_hat, config, plot)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction_locations)\n\u001b[0;32m--> 165\u001b[0m tp, fp, fn, loc_errors, things_to_plot \u001b[38;5;241m=\u001b[39m \u001b[43mget_acc_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_locations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m viewer \u001b[38;5;241m=\u001b[39m napari\u001b[38;5;241m.\u001b[39mview_points(things_to_plot[\u001b[38;5;241m0\u001b[39m], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall ground truth\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, face_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpink\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    168\u001b[0m viewer\u001b[38;5;241m.\u001b[39madd_image(mct\u001b[38;5;241m.\u001b[39mnumpy(), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 92\u001b[0m, in \u001b[0;36mget_acc_metrics\u001b[0;34m(y_hat, y)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculates accuracy metrics for a set of predicted and ground truth coordinates.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03mIs a true positive if the distance between the predicted and closest ground truth coordinate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    loc_errs (np.ndarray): location errors\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m tree \u001b[38;5;241m=\u001b[39m spatial\u001b[38;5;241m.\u001b[39mcKDTree(y)\n\u001b[0;32m---> 92\u001b[0m closest_dists, closest_nbrs \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# if predictions are within distance of the same point, only keep the first one\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# this is to avoid repeated counting of true positives that are actually false positives\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# it doesn't matter which one is closer in this case, as we are just making a count\u001b[39;00m\n\u001b[1;32m     97\u001b[0m removed_dup_indx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(closest_nbrs, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m_ckdtree.pyx:785\u001b[0m, in \u001b[0;36mscipy.spatial._ckdtree.cKDTree.query\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_ckdtree.pyx:1612\u001b[0m, in \u001b[0;36mscipy.spatial._ckdtree.num_points\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x must consist of vectors of length 8131 but has shape (3, 2421)"
     ]
    }
   ],
   "source": [
    "x = './dataset/fiddlercrab_corneas/whole/test_images_10/flammula_20190925_male_left-image.nii'\n",
    "y = './dataset/fiddlercrab_corneas/whole/test_labels_10/flammula_20190925_male_left-corneas.csv'\n",
    "y_hat = './output/flammula_20190925_male_left-image.logs_fiddlercrab_corneas_lightning_logs_version_26_checkpoints_last_prediction.nii'\n",
    "config = './configs/fiddlercrab_corneas.yaml'\n",
    "evaluate(x, y, y_hat, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd5947",
   "metadata": {},
   "source": [
    "Fiddler crab rhabdoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ef78f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File not found: \"output/dampieri_male_16-image.zoo_fiddlercrab_rhabdoms_version_4_checkpoints_last_prediction.nii.gz\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jake/projects/DeepRadiologist/evaluation.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=1'>2</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./dataset/fiddlercrab_rhabdoms/whole/test_labels_10/dampieri_male_16-rhabdoms.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=2'>3</a>\u001b[0m y_hat \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./output/dampieri_male_16-image.zoo_fiddlercrab_rhabdoms_version_4_checkpoints_last_prediction.nii.gz\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=4'>5</a>\u001b[0m evaluate(x, y, y_hat)\n",
      "\u001b[1;32m/home/jake/projects/DeepRadiologist/evaluation.ipynb Cell 6\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(x, y, y_hat, plot)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=128'>129</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(x, y, y_hat, plot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=129'>130</a>\u001b[0m     mct \u001b[39m=\u001b[39m tio\u001b[39m.\u001b[39mScalarImage(x)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=130'>131</a>\u001b[0m     prediction \u001b[39m=\u001b[39m tio\u001b[39m.\u001b[39;49mScalarImage(y_hat)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=132'>133</a>\u001b[0m     prediction_locations \u001b[39m=\u001b[39m locate_peaks(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=133'>134</a>\u001b[0m         y_hat,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=134'>135</a>\u001b[0m         save\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=137'>138</a>\u001b[0m         peak_min_val\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=138'>139</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=139'>140</a>\u001b[0m     ground_truth_locations\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mloadtxt(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=140'>141</a>\u001b[0m         y,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=141'>142</a>\u001b[0m         delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=142'>143</a>\u001b[0m         dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jake/projects/DeepRadiologist/evaluation.ipynb#ch0000005?line=143'>144</a>\u001b[0m     )\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/projects/DeepRadiologist/venv/lib/python3.8/site-packages/torchio/data/image.py:749\u001b[0m, in \u001b[0;36mScalarImage.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mType of ScalarImage is always torchio.INTENSITY\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    748\u001b[0m kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: INTENSITY})\n\u001b[0;32m--> 749\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/DeepRadiologist/venv/lib/python3.8/site-packages/torchio/data/image.py:161\u001b[0m, in \u001b[0;36mImage.__init__\u001b[0;34m(self, path, type, tensor, affine, check_nans, reader, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message, \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_path(path)\n\u001b[1;32m    163\u001b[0m \u001b[39mself\u001b[39m[PATH] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath)\n\u001b[1;32m    164\u001b[0m \u001b[39mself\u001b[39m[STEM] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m get_stem(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath)\n",
      "File \u001b[0;32m~/projects/DeepRadiologist/venv/lib/python3.8/site-packages/torchio/data/image.py:433\u001b[0m, in \u001b[0;36mImage._parse_path\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_single_path(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m path]\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_single_path(path)\n",
      "File \u001b[0;32m~/projects/DeepRadiologist/venv/lib/python3.8/site-packages/torchio/data/image.py:418\u001b[0m, in \u001b[0;36mImage._parse_single_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(message)\n\u001b[1;32m    417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (path\u001b[39m.\u001b[39mis_file() \u001b[39mor\u001b[39;00m path\u001b[39m.\u001b[39mis_dir()):   \u001b[39m# might be a dir with DICOM\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFile not found: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    419\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File not found: \"output/dampieri_male_16-image.zoo_fiddlercrab_rhabdoms_version_4_checkpoints_last_prediction.nii.gz\""
     ]
    }
   ],
   "source": [
    "x = './dataset/fiddlercrab_rhabdoms/whole/test_images_10/dampieri_male_16-image.nii.gz'\n",
    "y = './dataset/fiddlercrab_rhabdoms/whole/test_labels_10/dampieri_male_16-rhabdoms.csv'\n",
    "y_hat = './output/dampieri_male_16-image.zoo_fiddlercrab_rhabdoms_version_4_checkpoints_last_prediction.nii.gz'\n",
    "\n",
    "evaluate(x, y, y_hat)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e2de57d15965f72b89e8ca62bc4307d8ca62495ff41b03bd112e89b2b659458"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
