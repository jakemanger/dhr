{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Paraphronima corneas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "First open your heatmap in napari. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import torchio as tio\n",
    "\n",
    "# load in the nifti file with torchio\n",
    "image_path = '/media/jake/Dropbox_mirror/Smithsonian Dropbox/Jan Hemmi/hyperiid scans/Scans_nifti/Paraphronima_crassipes_f536_u1701837_head/Paraphronima_crassipes_f536_u1701837_head.nii'\n",
    "\n",
    "image = tio.ScalarImage(image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view file with napari\n",
    "import napari\n",
    "\n",
    "\n",
    "viewer = napari.view_image(image.numpy(), name='image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "In napari, label a few of the features (that are next to each other) to estimate the resample ratio, then save it as a csv file and load it in the next step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 2nd scan\n",
    "#RR = pd.read_csv('/home/jake/projects/dhr/FEG20190213_01_corneas_resample_ratio.csv')\n",
    "# 3rd scan\n",
    "# RR = pd.read_csv('/home/jake/projects/dhr/Cystisoma_sp_FEG221129_366_corneas_estimating_resample_ratio.csv')\n",
    "RR = pd.read_csv('resample_ratio_measurements/resample_ratio_measurement_Paraphronima_crassipes_f536_u1701837_head.csv')\n",
    "\n",
    "RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "coordinates = RR[['axis-1', 'axis-2', 'axis-3']].values\n",
    "dist_matrix = distance_matrix(coordinates, coordinates) #Create a distance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.fill_diagonal(dist_matrix, np.inf)\n",
    "\n",
    "# Find the nearest neighbor distance for each point\n",
    "nearest_distances = np.min(dist_matrix, axis=1)\n",
    "\n",
    "# Add the nearest distances to the dataframe\n",
    "RR['nearest_distance'] = nearest_distances\n",
    "RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nearest_distance = RR['nearest_distance'].mean()\n",
    "mean_nearest_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_ratio = mean_nearest_distance/10 #Makes average distance between features 10 voxels\n",
    "resample_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py infer -h #If you need help for parameters in infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Make inference first with 1 direction in the x, y, and z axis before creating inference in 3 directions. This will produce three files: two csv files (one for the resampled space, and the other not), and a nifty file with predictions.\n",
    "\n",
    "*Note: these files are currently saved to ./dhr/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference with 1 direction in x, y, and z\n",
    "# !python main.py infer configs/paraphronima_corneas.yaml -v '/media/jake/Dropbox_mirror/Smithsonian Dropbox/Jan Hemmi/hyperiid scans/Scans_nifti/Paraphronima_crassipes_f536_u1701837_head/Paraphronima_crassipes_f536_u1701837_head.nii' -m ./logs/paraphronima_corneas/lightning_logs/version_13/ -rr 3.1768202046528278 -nx 1 -ny 1 -nz 1\n",
    "\n",
    "# Inference in 3 directions with 0.25 threshold\n",
    "!python main.py infer configs/paraphronima_corneas.yaml -v '/media/jake/Dropbox_mirror/Smithsonian Dropbox/Jan Hemmi/hyperiid scans/Scans_nifti/Paraphronima_crassipes_f536_u1701837_head/Paraphronima_crassipes_f536_u1701837_head.nii' -m ./logs/paraphronima_corneas/lightning_logs/version_13/ -rr 3.1768202046528278 -nx 3 -ny 3 -nz 3 --average_threshold 0.25 -ipmv 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "You can then view your inference in napari. It might be useful to you, especially if you are trying many inferences with modified parameters, to evalute the performance of each and track estimated % of correct and incorrect inference points in an Excel spreadsheet for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "import torchio as tio\n",
    "\n",
    "\n",
    "image = tio.ScalarImage(image_path)\n",
    "\n",
    "heatmap_path = './output/Paraphronima_crassipes_f536_u1701837_head.logs_paraphronima_corneas_lightning_logs_version_13_checkpoints_last_x_3_y_3_z_3_average_threshold_0.25_prediction.nii'\n",
    "#Make sure to use resampled space csv here.\n",
    "y_hat_path = 'output/Paraphronima_crassipes_f536_u1701837_head.logs_paraphronima_corneas_lightning_logs_version_13_checkpoints_last_x_3_y_3_z_3_average_threshold_0.25_prediction_peak_min_val_0_25_method_center_of_mass.resampled_space_peaks.csv'\n",
    "\n",
    "heatmap = tio.ScalarImage(heatmap_path)\n",
    "\n",
    "\n",
    "viewer = napari.view_image(heatmap.numpy(), name='heatmap', contrast_limits=[0, 1])\n",
    "#viewer.add_image(image.numpy(), name='image')\n",
    "\n",
    "# load the coordinates to analyse\n",
    "def load_coordinates(path, flip_axes=False, mct_path=None):\n",
    "    locations = np.loadtxt(\n",
    "        path,\n",
    "        delimiter=',',\n",
    "        ndmin=2,\n",
    "        dtype=np.float64\n",
    "    )\n",
    "    if not flip_axes: \n",
    "        return locations.tolist()\n",
    "\n",
    "    if not mct_path:\n",
    "        raise Exception('You must specify `mct_path` if you need to flip_axes')\n",
    "\n",
    "    mct = tio.ScalarImage(mct_path)\n",
    "    locations[:,0] = mct.shape[1] - locations[:,0]\n",
    "    locations[:,1] = mct.shape[2] - locations[:,1]\n",
    "\n",
    "    return locations.tolist()\n",
    "\n",
    "\n",
    "y_hat = load_coordinates(y_hat_path)\n",
    "\n",
    "\n",
    "viewer.add_points(y_hat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
