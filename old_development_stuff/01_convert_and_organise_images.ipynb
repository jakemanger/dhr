{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup\n",
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from shutil import copyfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define locations for data\n",
    "We seperate output directories into raw and non-raw. This is because we need to do a set of preprocessing stages to the raw data before we make the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "input_image_dir = '//media/jake/1tb_ssd/mctv_analysis/Head Scans'\n",
    "input_labels_dir = '//home/jake/projects/mctv_resfiles'\n",
    "\n",
    "# outputs\n",
    "main_dir = '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data'\n",
    "raw_image_dir = '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images'\n",
    "raw_labels_dir = '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_labels'\n",
    "image_dir = '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/images'\n",
    "labels_dir = '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/labels'\n",
    "\n",
    "if not os.path.isdir(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "if not os.path.isdir(labels_dir):\n",
    "    os.makedirs(labels_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate images\n",
    "Our original images are organised in a messy way. Let's collate them together and fix that up.\n",
    "\n",
    "First, let's find all the images in the input image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42 nifti files\n",
      "Found 86 dicom directories\n"
     ]
    }
   ],
   "source": [
    "nii_files = []\n",
    "dicom_dirs = []\n",
    "for root, dirs, files in os.walk(input_image_dir):\n",
    "    for i, file in enumerate(files):\n",
    "        if file.endswith('.nii'):\n",
    "            nii_files.append(root + '/' + file)\n",
    "        if file.endswith('.dcm'):\n",
    "            dicom_dirs.append(root)\n",
    "\n",
    "# remove duplicate dicom_dirs\n",
    "dicom_dirs = list(set(dicom_dirs))\n",
    "\n",
    "print('Found ' + str(len(nii_files)) + ' nifti files')\n",
    "print('Found ' + str(len(dicom_dirs)) + ' dicom directories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//media/jake/1tb_ssd/mctv_analysis/head_scans/Brachyscelus.nii',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Vibilia_01_FEG191211_087_filterted.nii',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Paraphronima_FEG200130_103_head_04.nii',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Scypholanceola_head_02_FEG191022_076.nii',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Platyscelus_02_FEG191112_082.nii',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Phronima_05_FEG200107_090.nii',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Paraphronima_FEG200130_102_head_05.nii',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Hyperia 01_segmented eyes.nii',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Phronima_04_FEG200107_089.nii',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/psyllid_20190906_male_eye/psyllid_20190906_male_eye.nii']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nii_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//media/jake/1tb_ssd/mctv_analysis/head_scans/Scina_02_sp_2_1450794_slices',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Eupronoe_01_sp_6_F',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Cystisoma_FEG20190212_01_head',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/P_crassipes_FEG190213_002_head_eyesdamaged',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Pronoe_sp_6_E',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Paraphronima_FEG181024_head_sp_3_1423158a',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/P_crassipes_FEG200130_104',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Phronima_head_1450842_head_2',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/flammula_male_23_6_left',\n",
       " '//media/jake/1tb_ssd/mctv_analysis/head_scans/Paraphronima_head_04_FEG200130_103']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicom_dirs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move nifti to raw images folder\n",
    "Let's move all the nifti files to the raw_images directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File //media/jake/data/jake/mctnet_data/raw_images/Brachyscelus.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/Vibilia_01_FEG191211_087_filterted.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/Paraphronima_FEG200130_103_head_04.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/Scypholanceola_head_02_FEG191022_076.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/Platyscelus_02_FEG191112_082.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/Phronima_05_FEG200107_090.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/Paraphronima_FEG200130_102_head_05.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/Hyperia 01_segmented eyes.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/Phronima_04_FEG200107_089.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/psyllid_20190906_male_eye.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/crab-eyestalk_FOV3mm-PIX2.9micron.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/dampieri_male_16.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/diurnal_tarsata.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/flammula_20180307.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/flammula_20190925_male_left.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/flammula_20200327_female_left_178_fullres_cropped.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/neohelice_20190616_1_cropped.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/phronima_20180403.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/psyllid_20190906_female_eye.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/dampieri_20181221_female_left.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/20181221L_female_cropped.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/flammula_female_left_17.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/dampieri_female_18.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/dampieri_female_right_19.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/dampieri_20200218_male_left_1676.nii already exists, so skipped this copy\n",
      "\n",
      "File //media/jake/data/jake/mctnet_data/raw_images/dampieri_20200218_male_right_1676.nii already exists, so skipped this copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in nii_files:\n",
    "    p = Path(d)\n",
    "    filename = p.stem\n",
    "    new_path = raw_image_dir + \"/\" + filename + '.nii'\n",
    "    if not os.path.isfile(new_path):\n",
    "        copyfile(d, new_path)\n",
    "        print(f'Copied nifti {d} to {new_path}\\n')\n",
    "    else:\n",
    "        print(f'File {new_path} already exists, so skipped this copy\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert dicom to nifti\n",
    "A bunch of files are in the dicom format. Let's convert these to nifti, so that all our data are consistent and in single files.\n",
    "\n",
    "To do this, we will be using dcm2niix found at https://github.com/rordenlab/dcm2niix\n",
    "This can be installed on linux via\n",
    "```\n",
    "sudo apt install dicom2nixx\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the dicom directories in `dicom_dirs` but we also need to extract the output path and the filename. Let's do that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ { 'filename': 'Schypholanceola_FEG190802_038_01_head',\n",
      "    'in_dir': '//media/jake/1tb_ssd/mctv_analysis/Head '\n",
      "              'Scans/Schypholanceola_FEG190802_038_01_head',\n",
      "    'out_dir': '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images'},\n",
      "  { 'filename': 'Paraphronima_sp_8_1423158-slices',\n",
      "    'in_dir': '//media/jake/1tb_ssd/mctv_analysis/Head '\n",
      "              'Scans/Phronima_sp_5_USNM1450842/Paraphronima_sp_8_1423158-slices',\n",
      "    'out_dir': '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images'},\n",
      "  { 'filename': 'Streetsia_sp_4_1450785b',\n",
      "    'in_dir': '//media/jake/1tb_ssd/mctv_analysis/Head '\n",
      "              'Scans/Streetsia_head_sp_4_1450785b/Streetsia_sp_4_1450785b',\n",
      "    'out_dir': '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images'},\n",
      "  { 'filename': 'FEG210804_117-Phrosina-semilunata-body-registered',\n",
      "    'in_dir': '//media/jake/1tb_ssd/mctv_analysis/Head '\n",
      "              'Scans/FEG210804_117-Phrosina-semilunata-body-registered',\n",
      "    'out_dir': '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images'},\n",
      "  { 'filename': 'Phronima_1450842_body_2_slices',\n",
      "    'in_dir': '//media/jake/1tb_ssd/mctv_analysis/Head '\n",
      "              'Scans/Phronima_1450842_body_2_slices',\n",
      "    'out_dir': '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "conversion_info = []\n",
    "\n",
    "for d in dicom_dirs:\n",
    "    p = Path(d)\n",
    "    filename = p.stem\n",
    "    #new_path = raw_image_dir + \"/\" + filename + '.nii'\n",
    "\n",
    "    conversion_info.append(\n",
    "        dict(\n",
    "            in_dir=d,\n",
    "            out_dir=raw_image_dir,\n",
    "            filename=filename\n",
    "        )\n",
    "    )\n",
    "\n",
    "# print first 5 to check if looks ok\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(conversion_info[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a yaml file to tell dicom2niix what to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data = dict(\n",
    "    Options = dict(\n",
    "      isGz='false',\n",
    "      isFlipY='false',\n",
    "      isVerbose='false',\n",
    "      isCreateBIDS='false',\n",
    "      isOnlySingleFile='false'\n",
    "    ),\n",
    "    Files = conversion_info\n",
    ")\n",
    "with open('dicom2niix_batch_info.yml', 'w') as outfile:\n",
    "    yaml.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and let's run dicom2niix (warning this may generate a huge output, so clear this afterwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dcm2niibatch dicom2niix_batch_info.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the scans that are in the directory to make sure everything is set up properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70 dicom directories that should have been converted to \n",
      "        nifti and 26 nifti files that should have been moved \n",
      "        i.e. a total of 96 nifti files.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'There are {len(dicom_dirs)} dicom directories that should have been converted to \\n\\\n",
    "        nifti and {len(nii_files)} nifti files that should have been moved \\n\\\n",
    "        i.e. a total of {len(dicom_dirs) + len(nii_files)} nifti files.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 151 nifti files in the output folder\n"
     ]
    }
   ],
   "source": [
    "raw_nii_files = []\n",
    "for file in os.listdir(raw_image_dir):\n",
    "    if file.endswith('.nii'):\n",
    "        raw_nii_files.append(raw_image_dir + '/' + file)\n",
    "\n",
    "\n",
    "print(f'There are {len(raw_nii_files)} nifti files in the output folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "the number of files do not match up",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5234/3379254306.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_nii_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicom_dirs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnii_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'the number of files do not match up'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: the number of files do not match up"
     ]
    }
   ],
   "source": [
    "assert len(raw_nii_files) == (len(dicom_dirs) + len(nii_files)), 'the number of files do not match up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images/Paraphronima_head_05_FEG200130_102.nii', '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images/Vibilia_FEG191112_081_blurrya.nii', '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images/Phronima_02_head_1450842_head_3.nii', '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images/Phronima_01_head_sp_5_USNM1450842.nii', '//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jake/mctnet_data/raw_images/FEG191028_078_dcm.nii']\n"
     ]
    }
   ],
   "source": [
    "print(raw_nii_files[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above assert statement causes an error, then that means you may need to manually sort through these files to see what might have happened wrong in the conversion process. If some did not convert, then try to convert them manually via a gui interface. If there are too many files, go through them and check to see which scan matches up with the annotations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Checking and linking the image files to the annotated files manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a csv file with the paths to all the image files we moved/converted. Then, let's add the annotated files we know of to this csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file_path</th>\n",
       "      <th>raw_annotated_file_path</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>//mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_file_path  \\\n",
       "0    //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "1    //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "2    //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "3    //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "4    //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "..                                                 ...   \n",
       "146  //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "147  //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "148  //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "149  //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "150  //mnt/d37c99c5-3b94-47b9-9965-c66fd9a16e23/jak...   \n",
       "\n",
       "    raw_annotated_file_path name  \n",
       "0                                 \n",
       "1                                 \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "..                      ...  ...  \n",
       "146                               \n",
       "147                               \n",
       "148                               \n",
       "149                               \n",
       "150                               \n",
       "\n",
       "[151 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    " {\n",
    "    'image_file_path': raw_nii_files,\n",
    "    'raw_annotated_file_path': '',\n",
    "    'name': '',\n",
    "    'converted_from_dicom': ''\n",
    " }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_image_info.csv already exists, so did not overwrite.\n"
     ]
    }
   ],
   "source": [
    "newfile_path = 'raw_image_info.csv'\n",
    "if not os.path.isfile(newfile_path):\n",
    "    df.to_csv('raw_image_info.csv', index=False)\n",
    "else:\n",
    "    print(newfile_path + ' already exists, so did not overwrite.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open this up with libreoffice (alternatively, just open the file with another program like excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javaldx: Could not find a Java Runtime Environment!\n",
      "Please ensure that a JVM and the package libreoffice-java-common\n",
      "is installed.\n",
      "If it is already installed then try removing ~/.config/libreoffice/4/user/config/javasettings_Linux_*.xml\n",
      "Warning: failed to read path from javaldx\n"
     ]
    }
   ],
   "source": [
    "!libreoffice --calc raw_image_info.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created this csv file and filled it in, you should be ready to move onto step 02."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert dicom to nifti alternative (doesn't seem to work too well with some dicom files.\n",
    "# appears to be a problem with dicom2nifti or its inability to deal with file errors)\n",
    "\n",
    "Let's start by making a function that can convert our dicom directories to nifti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nifti_to_dicom(d):\n",
    "    print(f'Starting conversion of {d} \\n...\\n')\n",
    "\n",
    "    p = Path(d)\n",
    "    filename = p.stem\n",
    "    new_path = raw_image_dir + \"/\" + filename + '.nii'\n",
    "    \n",
    "    if not os.path.isfile(new_path):\n",
    "        dicom2nifti.dicom_series_to_nifti(d, new_path, reorient_nifti=True)\n",
    "        print(f'Converted dicom {d} to {new_path}\\n')\n",
    "    else:\n",
    "        print(f'File {new_path} already exists, so skipped this conversion\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this faster, let's create some multiprocessing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# split a list into evenly sized chunks\n",
    "def chunks(l, n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def do_job(job_id, data, func):\n",
    "    for item in data:\n",
    "        print(f'Worker {job_id} doing job\\n')\n",
    "        func(item)\n",
    "\n",
    "def dispatch_jobs(job_number, data, func):\n",
    "    total = len(data)\n",
    "    chunk_size = total / job_number\n",
    "    slice = chunks(data, int(chunk_size))\n",
    "    jobs = []\n",
    "\n",
    "    for i, s in enumerate(slice):\n",
    "        j = multiprocessing.Process(target=do_job, args=(i, s, func))\n",
    "        jobs.append(j)\n",
    "    for j in jobs:\n",
    "        j.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run this function over our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 70 dicom scans to nifti\n",
      "Worker 0 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/flammula_male_23_6_left \n",
      "...\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Eupronoe_03_sp_6_A \n",
      "...\n",
      "Worker 1 doing job\n",
      "\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/flammula_male_23_6_left.nii already exists, so skipped this conversion\n",
      "\n",
      "\n",
      "Worker 0 doing jobWorker 2 doing job\n",
      "\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Eupronoe_03_sp_6_A/Leptocotis_FEG190214_004a_body_slices \n",
      "...\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Hyperia_FEG190604_013A-slices-body \n",
      "...\n",
      "\n",
      "\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/Leptocotis_FEG190214_004a_body_slices.nii already exists, so skipped this conversion\n",
      "Worker 3 doing job\n",
      "\n",
      "Worker 0 doing jobStarting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Lanceola_01_head_FEG190802_037 \n",
      "...\n",
      "Worker 4 doing jobThat took 0.05334925651550293 seconds\n",
      "\n",
      "\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Schypholanceola_FEG190801_036_head \n",
      "...\n",
      "\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/Lanceola_01_head_FEG190802_037.nii already exists, so skipped this conversion\n",
      "\n",
      "\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Paraphronima_FEG191028_078/FEG191028_078_dcm \n",
      "...\n",
      "Worker 5 doing job\n",
      "Worker 3 doing job\n",
      "\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Paraphronima_FEG181024_03_head_sp3_1423158b \n",
      "...\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/P_crassipes_FEG191022_077B_highpriority \n",
      "...\n",
      "\n",
      "\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/P_crassipes_FEG191022_077B_highpriority.nii already exists, so skipped this conversion\n",
      "\n",
      "Worker 6 doing jobWorker 5 doing job\n",
      "\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Cystisoma_FEG190801_035_brain \n",
      "...\n",
      "\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Cystisoma_FEG20190212_01_head \n",
      "...\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/Cystisoma_FEG190801_035_brain.nii already exists, so skipped this conversion\n",
      "\n",
      "\n",
      "Worker 5 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Hyperia_head_7_1432188A \n",
      "...\n",
      "\n",
      "Converted dicom /media/jake/1tb_ssd/mctv_analysis/head_scans/Hyperia_FEG190604_013A-slices-body to /media/jake/data/jake/mctnet_data/raw_images/Hyperia_FEG190604_013A-slices-body.nii\n",
      "\n",
      "Worker 2 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Vibilia_FEG191112_081_blurry \n",
      "...\n",
      "\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/Vibilia_FEG191112_081_blurry.nii already exists, so skipped this conversion\n",
      "\n",
      "Worker 2 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Phrosina_FEG200310_110 \n",
      "...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_767898/2836884920.py\", line 10, in do_job\n",
      "    func(item)\n",
      "  File \"/tmp/ipykernel_767898/1759632588.py\", line 9, in convert_nifti_to_dicom\n",
      "    dicom2nifti.dicom_series_to_nifti(d, new_path, reorient_nifti=True)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 78, in dicom_series_to_nifti\n",
      "    return dicom_array_to_nifti(dicom_input, output_file, reorient_nifti)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 112, in dicom_array_to_nifti\n",
      "    if not are_imaging_dicoms(dicom_list):\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 151, in are_imaging_dicoms\n",
      "    if common.is_philips(dicom_input):\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/common.py\", line 102, in is_philips\n",
      "    header = dicom_input[0]\n",
      "IndexError: list index out of range\n",
      "Process Process-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_767898/2836884920.py\", line 10, in do_job\n",
      "    func(item)\n",
      "  File \"/tmp/ipykernel_767898/1759632588.py\", line 9, in convert_nifti_to_dicom\n",
      "    dicom2nifti.dicom_series_to_nifti(d, new_path, reorient_nifti=True)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 78, in dicom_series_to_nifti\n",
      "    return dicom_array_to_nifti(dicom_input, output_file, reorient_nifti)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 112, in dicom_array_to_nifti\n",
      "    if not are_imaging_dicoms(dicom_list):\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 151, in are_imaging_dicoms\n",
      "    if common.is_philips(dicom_input):\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/common.py\", line 102, in is_philips\n",
      "    header = dicom_input[0]\n",
      "IndexError: list index out of range\n",
      "Process Process-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_767898/2836884920.py\", line 10, in do_job\n",
      "    func(item)\n",
      "  File \"/tmp/ipykernel_767898/1759632588.py\", line 9, in convert_nifti_to_dicom\n",
      "    dicom2nifti.dicom_series_to_nifti(d, new_path, reorient_nifti=True)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 78, in dicom_series_to_nifti\n",
      "    return dicom_array_to_nifti(dicom_input, output_file, reorient_nifti)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 112, in dicom_array_to_nifti\n",
      "    if not are_imaging_dicoms(dicom_list):\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 151, in are_imaging_dicoms\n",
      "    if common.is_philips(dicom_input):\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/common.py\", line 102, in is_philips\n",
      "    header = dicom_input[0]\n",
      "IndexError: list index out of range\n",
      "Process Process-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_767898/2836884920.py\", line 10, in do_job\n",
      "    func(item)\n",
      "  File \"/tmp/ipykernel_767898/1759632588.py\", line 9, in convert_nifti_to_dicom\n",
      "    dicom2nifti.dicom_series_to_nifti(d, new_path, reorient_nifti=True)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 78, in dicom_series_to_nifti\n",
      "    return dicom_array_to_nifti(dicom_input, output_file, reorient_nifti)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 118, in dicom_array_to_nifti\n",
      "    results = convert_generic.dicom_to_nifti(dicom_list, output_file)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_generic.py\", line 77, in dicom_to_nifti\n",
      "    data = common.get_volume_pixeldata(dicom_input)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/common.py\", line 210, in get_volume_pixeldata\n",
      "    vol = numpy.concatenate(slices, axis=0)\n",
      "  File \"<__array_function__ internals>\", line 5, in concatenate\n",
      "ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 613 and the array at index 1 has size 621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dicom /media/jake/1tb_ssd/mctv_analysis/head_scans/Cystisoma_FEG20190212_01_head to /media/jake/data/jake/mctnet_data/raw_images/Cystisoma_FEG20190212_01_head.nii\n",
      "\n",
      "Worker 6 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Scina_02_sp_2_1450794_slices \n",
      "...\n",
      "\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/Scina_02_sp_2_1450794_slices.nii already exists, so skipped this conversion\n",
      "\n",
      "Worker 6 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Leptocotis_01_head_FEG190214_005a \n",
      "...\n",
      "\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/Leptocotis_01_head_FEG190214_005a.nii already exists, so skipped this conversion\n",
      "\n",
      "Worker 6 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Vibilia_FEG191113_084_blurry \n",
      "...\n",
      "\n",
      "Converted dicom /media/jake/1tb_ssd/mctv_analysis/head_scans/Schypholanceola_FEG190801_036_head to /media/jake/data/jake/mctnet_data/raw_images/Schypholanceola_FEG190801_036_head.nii\n",
      "\n",
      "Worker 0 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/P_gracilis_FEG190730_032B_01_head \n",
      "...\n",
      "\n",
      "Converted dicom /media/jake/1tb_ssd/mctv_analysis/head_scans/Vibilia_FEG191113_084_blurry to /media/jake/data/jake/mctnet_data/raw_images/Vibilia_FEG191113_084_blurry.nii\n",
      "\n",
      "Converted dicom /media/jake/1tb_ssd/mctv_analysis/head_scans/P_gracilis_FEG190730_032B_01_head to /media/jake/data/jake/mctnet_data/raw_images/P_gracilis_FEG190730_032B_01_head.nii\n",
      "\n",
      "Worker 0 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Cystisoma_FEG190730_030_head \n",
      "...\n",
      "\n",
      "Converted dicom /media/jake/1tb_ssd/mctv_analysis/head_scans/Cystisoma_FEG190730_030_head to /media/jake/data/jake/mctnet_data/raw_images/Cystisoma_FEG190730_030_head.nii\n",
      "\n",
      "Worker 0 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Cystisoma_FEG190802_040_brain \n",
      "...\n",
      "\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/Cystisoma_FEG190802_040_brain.nii already exists, so skipped this conversion\n",
      "\n",
      "Worker 0 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/P_crassipes_FEG190801_034_head \n",
      "...\n",
      "\n",
      "File /media/jake/data/jake/mctnet_data/raw_images/P_crassipes_FEG190801_034_head.nii already exists, so skipped this conversion\n",
      "\n",
      "Worker 0 doing job\n",
      "Starting conversion of /media/jake/1tb_ssd/mctv_analysis/head_scans/Pronoe_sp_6_D \n",
      "...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_767898/2836884920.py\", line 10, in do_job\n",
      "    func(item)\n",
      "  File \"/tmp/ipykernel_767898/1759632588.py\", line 9, in convert_nifti_to_dicom\n",
      "    dicom2nifti.dicom_series_to_nifti(d, new_path, reorient_nifti=True)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 78, in dicom_series_to_nifti\n",
      "    return dicom_array_to_nifti(dicom_input, output_file, reorient_nifti)\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 112, in dicom_array_to_nifti\n",
      "    if not are_imaging_dicoms(dicom_list):\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/convert_dicom.py\", line 151, in are_imaging_dicoms\n",
      "    if common.is_philips(dicom_input):\n",
      "  File \"/home/jake/projects/mctnet/venv/lib/python3.8/site-packages/dicom2nifti/common.py\", line 102, in is_philips\n",
      "    header = dicom_input[0]\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "print(f'Converting {len(dicom_dirs)} dicom scans to nifti')\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "dispatch_jobs(6, dicom_dirs, convert_nifti_to_dicom)\n",
    "\n",
    "print('That took {} seconds'.format(time.time() - starttime))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f726fa9e3d96265230c4503e543f5c3f73ae5ded033c480caee9e2a2a13a4b04"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
